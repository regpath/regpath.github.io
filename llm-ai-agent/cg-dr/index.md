# LLMì„ í™œìš©í•œ AI ì—ì´ì „íŠ¸ ê°œë°œ ì…ë¬¸: í˜¼ì ê³µë¶€ ê°€ì´ë“œ

**ì´ ê°€ì´ë“œëŠ”** *â€œDo it! LLMì„ í™œìš©í•œ AI ì—ì´ì „íŠ¸ ê°œë°œ ì…ë¬¸â€* ì±…ì˜ ë‚´ìš©ì„ í† ëŒ€ë¡œ, í˜¼ìì„œ ë‹¨ê³„ë³„ë¡œ ì‹¤ìŠµí•˜ê³  í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ ì •ë¦¬í•œ **ì£¼í”¼í„° ë…¸íŠ¸ë¶ ìŠ¤íƒ€ì¼ ìë£Œ**ì…ë‹ˆë‹¤. Pythonê³¼ ì£¼í”¼í„° ë…¸íŠ¸ë¶ í™˜ê²½ì— ìµìˆ™í•˜ì§€ë§Œ, ì»´í“¨í„° ê³µí•™ ì „ê³µìëŠ” ì•„ë‹ˆë©° LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì²˜ìŒ ì ‘í•˜ëŠ” ë…ìë¥¼ ì—¼ë‘ì— ë‘ì—ˆìŠµë‹ˆë‹¤. VS Codeì˜ Jupyter í™•ì¥ê³¼ OpenAI í˜¸í™˜ APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ê°€ì •í•˜ë©°, **ê° ì„¹ì…˜ë§ˆë‹¤ ê°œë… ì„¤ëª…ê³¼ í•¨ê»˜ í•µì‹¬ ì½”ë“œ ì˜ˆì‹œ**ë¥¼ í¬í•¨í•˜ì˜€ìŠµë‹ˆë‹¤. íšŒì‚¬ ë“± ë³´ì•ˆ ì œí•œì´ ìˆëŠ” í™˜ê²½ì—ì„œ ì‹¤ìŠµí•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ **íŠ¹ìˆ˜ ìƒí™©ì—ì„œì˜ ëŒ€ì²˜ë²•**ë„ í•¨ê»˜ ì„¤ëª…í•©ë‹ˆë‹¤.

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼ê°€ë‹¤ ë³´ë©´ **GPT API í™œìš© ê¸°ë³¸ê¸°ë¶€í„°, í…ìŠ¤íŠ¸/ìŒì„±/ì´ë¯¸ì§€ ì²˜ë¦¬, LangChainì„ ì´ìš©í•œ ëŒ€í™” ë©”ëª¨ë¦¬ì™€ íˆ´ í†µí•©, ê²€ìƒ‰ ê¸°ëŠ¥ ì—°ê³„, ìµœì¢…ì ìœ¼ë¡œëŠ” ì—¬ëŸ¬ ì—ì´ì „íŠ¸ë¥¼ ì¡°í•©í•œ ê³ ê¸‰ í”„ë¡œì íŠ¸ êµ¬í˜„**ê¹Œì§€ í•œê±¸ìŒì”© ë°°ìš°ê²Œ ë©ë‹ˆë‹¤. 

---

## OpenAI API ê¸°ë³¸ ì‚¬ìš©ë²•

ì‹œì‘í•˜ê¸°ì— ì•ì„œ, OpenAIì˜ GPT API(ì±—GPT API)ë¥¼ í˜¸ì¶œí•˜ëŠ” ê¸°ë³¸ ë°©ë²•ì„ ì•Œì•„ë´…ì‹œë‹¤. OpenAI ê³„ì •ì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ í™˜ê²½ë³€ìˆ˜ `OPENAI_API_KEY`ì— ì„¤ì •í•˜ê±°ë‚˜ ì½”ë“œì—ì„œ ì§ì ‘ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤. ì£¼í”¼í„° ë…¸íŠ¸ë¶ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‚¤ë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
import openai
openai.api_key = "ë°œê¸‰ë°›ì€-ë‚˜ì˜-APIí‚¤"
```

ë˜ëŠ” `.env` íŒŒì¼ì´ë‚˜ OS í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ë„ ìˆìŠµë‹ˆë‹¤ (ì˜ˆ: `python-dotenv` ì‚¬ìš©). íšŒì‚¬ ë‚´ íì‡„ë§ ë“±ì—ì„œ ìì²´ í˜¸í™˜ APIë¥¼ ì“°ëŠ” ê²½ìš°, OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ `api_base` ì—”ë“œí¬ì¸íŠ¸ë¥¼ ë³€ê²½í•´ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë‚´ë¶€ í˜¸í™˜ API URLì´ `https://corp-api.example.com/v1`ë¼ë©´ `openai.api_base = "https://corp-api.example.com/v1"` ê³¼ ê°™ì´ ì§€ì •í•˜ë©´ í˜¸í™˜ë©ë‹ˆë‹¤.

**ëª¨ë¸ ì„ íƒ:** OpenAI APIì—ì„œëŠ” `"gpt-3.5-turbo"`, `"gpt-4"` ë“±ì˜ ëª¨ë¸ëª…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì±…ì˜ ì½”ë“œì—ì„œëŠ” `gpt-4` ê¸°ë°˜ ì‚¬ì„¤ ëª¨ë¸ ëª…ì‹œë¥¼ ìœ„í•´ `"gpt-4o"`ì²˜ëŸ¼ ì ‘ë¯¸ì‚¬ë¥¼ ë¶™ì—¬ í‘œê¸°í–ˆìœ¼ë‚˜(ì˜ˆ: ), ì‹¤ì œë¡œëŠ” **ì‚¬ìš© ê¶Œí•œì´ ìˆëŠ” ëª¨ë¸ ëª…**ì„ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆì œë¥¼ ì‹¤í–‰í•  ë•Œ ì ‘ê·¼ ê°€ëŠ¥í•œ ëª¨ë¸ë¡œ ë³€ê²½í•˜ì„¸ìš”.

**í•œê¸€ ì…ì¶œë ¥:** GPT APIëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë‹¤êµ­ì–´ë¥¼ ì§€ì›í•˜ë¯€ë¡œ í”„ë¡¬í”„íŠ¸ì™€ ì‘ë‹µì„ í•œê¸€ë¡œ ì£¼ê³ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë§Œ ì •í™•í•œ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ **ì—­í• (Role) ì§€ì‹œì–´ì™€ êµ¬ì²´ì ì¸ ì§€ì¹¨**ì„ í”„ë¡¬í”„íŠ¸ì— ëª…ì‹œí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— AIì˜ ì—­í• ê³¼ ì¶œë ¥ í˜•ì‹ì„ í•œêµ­ì–´ë¡œ ìƒì„¸íˆ ì•Œë ¤ì£¼ëŠ” ì‹ì…ë‹ˆë‹¤.

ì´ì œ ë³¸ê²©ì ì¸ ê° ì±•í„°ë³„ ì£¼ì œ í•™ìŠµì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.

---

## ë¬¸ì„œ ìš”ì•½: PDF í…ìŠ¤íŠ¸ ì²˜ë¦¬ì™€ LLM ìš”ì•½

**ëŒ€ìš©ëŸ‰ í…ìŠ¤íŠ¸ ìš”ì•½**ì€ LLM í™œìš©ì˜ ëŒ€í‘œ ì‚¬ë¡€ì…ë‹ˆë‹¤. ì±…ì˜ 4ì¥ì—ì„œëŠ” **ì—°êµ¬ ë³´ê³ ì„œ PDF ë¬¸ì„œ**ë¥¼ ì½ì–´ ìš”ì•½í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¹ë‹ˆë‹¤. ì£¼ìš” ë‹¨ê³„ëŠ” **PDF -> í…ìŠ¤íŠ¸ ë³€í™˜**ê³¼ **í…ìŠ¤íŠ¸ -> ìš”ì•½ ìƒì„±**ìœ¼ë¡œ ë‚˜ë‰©ë‹ˆë‹¤.

1. **PDFë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ**  
   `PyPDF2`ë‚˜ `pdfplumber` ë“±ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ PDF íŒŒì¼ì˜ ë³¸ë¬¸ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. ì¶”ì¶œí•œ ì›ë¬¸ í…ìŠ¤íŠ¸ëŠ” ìš©ëŸ‰ì´ í¬ë¯€ë¡œ í•„ìš”ì‹œ **ì „ì²˜ë¦¬(í—¤ë”/í‘¸í„° ì œê±° ë“±)**ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

2. **LLMì—ê²Œ ìš”ì•½ ìš”ì²­**  
   ```python
   with open(file_path, 'r', encoding='utf-8') as f:
       txt = f.read()

   system_prompt = f'''
   ë„ˆëŠ” ë‹¤ìŒ ê¸€ì„ ìš”ì•½í•˜ëŠ” ë´‡ì´ë‹¤. ì•„ë˜ ê¸€ì„ ì½ê³ , ì €ìì˜ ë¬¸ì œ ì¸ì‹ê³¼ ì£¼ì¥ì„ íŒŒì•…í•˜ê³ , ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•˜ë¼. 

   ì‘ì„±í•´ì•¼ í•˜ëŠ” í¬ë§·ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 
   # ì œëª©
   ## ì €ìì˜ ë¬¸ì œ ì¸ì‹ ë° ì£¼ì¥ (15ë¬¸ì¥ ì´ë‚´)
   ## ì €ì ì†Œê°œ

   =============== ì´í•˜ í…ìŠ¤íŠ¸ ===============
   {txt}
   '''
   ```
   ì´í›„ GPT í˜¸ì¶œë¡œ ìš”ì•½ ê²°ê³¼ë¥¼ ë°›ìŠµë‹ˆë‹¤.

3. **ì‘ë‹µ ì²˜ë¦¬**  
   GPTê°€ ìƒì„±í•œ ìš”ì•½ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ê±°ë‚˜ ì¶œë ¥í•©ë‹ˆë‹¤.

> **íšŒì‚¬ í™˜ê²½:** PDF ë‘ ê°œ(ì„œìš¸Â·ë‰´ìš• ê³„íš ë³´ê³ ì„œ)ê°€ í•„ìš”í•œë° ì‚¬ë‚´ ë§ ì°¨ë‹¨ ì‹œ ì™¸ë¶€ì—ì„œ USBë¡œ ê°€ì ¸ì˜¤ê±°ë‚˜ ëŒ€ì²´ ê³µê°œ ë¬¸ì„œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

---

## ìŒì„± ì¸ì‹ê³¼ ìš”ì•½: Whisperë¥¼ í™œìš©í•œ STT

ìŒì„± ë…¹ìŒ íŒŒì¼ì„ ë°›ì•„ **1) í…ìŠ¤íŠ¸ë¡œ ë³€í™˜(STT)**í•˜ê³ , **2) ì¤‘ìš”í•œ ë‚´ìš© ìš”ì•½**ê¹Œì§€ ì§„í–‰í•©ë‹ˆë‹¤.

| ë°©ë²• | ì¥ì  | ë‹¨ì  |
|------|------|------|
| OpenAI Whisper API | ì„¤ì¹˜ ì—†ì´ ê³ ì •ë°€ | ì¸í„°ë„· í•„ìš”Â·ë¹„ìš© |
| Hugging Face Whisper | ì˜¤í”„ë¼ì¸ ê°€ëŠ¥ | ì²« ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•„ìš”Â·ì†ë„ |

### ì˜ˆì‹œ (OpenAI Whisper)

```python
import openai
audio_file = open("meeting_record.mp3", "rb")
transcript = openai.Audio.transcribe("whisper-1", audio_file)
print(transcript['text'])
```

### ì˜ˆì‹œ (Hugging Face Whisper)

```python
from transformers import pipeline
stt_pipeline = pipeline(task="automatic-speech-recognition",
                        model="openai/whisper-small", device=0)
result = stt_pipeline("meeting_record.mp3")
text = result['text']
```

> **íšŒì‚¬ í™˜ê²½:** Hugging Face ëª¨ë¸(ìˆ˜ë°± MB)ì„ ì‚¬ì „ì— ë‹¤ìš´ë¡œë“œí•´ ìºì‹œ í´ë”ë¥¼ ë³µì‚¬í•´ ë‘¡ë‹ˆë‹¤.

---

## ì´ë¯¸ì§€ ë¶„ì„ê³¼ í™œìš©: ì‹œê° ì •ë³´ ì²˜ë¦¬

ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„± â†’ LLM í™œìš©

```python
from transformers import BlipProcessor, BlipForConditionalGeneration
processor = BlipProcessor.from_pretrained("Salesforce/blip2-flan-t5-xl")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip2-flan-t5-xl")

image = Image.open('busan_dive.jpg')
inputs = processor(image, "ì‚¬ì§„ ì„¤ëª…ë¥¼ í•œêµ­ì–´ë¡œ ìì„¸íˆ ì¨ì¤˜.", return_tensors="pt")
result = model.generate(**inputs)
description = processor.decode(result[0], skip_special_tokens=True)
```

ì´í›„ GPTì—ê²Œ `description`ì„ ì£¼ê³  Q&A, í€´ì¦ˆ ë“±ì„ ìƒì„±.

> **íšŒì‚¬ í™˜ê²½:** ëª¨ë¸ ìš©ëŸ‰ í¼. ë¡œì»¬ Vision APIê°€ ìˆìœ¼ë©´ íƒœê·¸ë§Œ ë°›ì•„ì„œ LLMì— ë„˜ê¸°ëŠ” ë°©ë²•ë„ ê°€ëŠ¥.

---

## GPT í•¨ìˆ˜ í˜¸ì¶œê³¼ ë„êµ¬ í†µí•©

OpenAI Function Calling + LangChain Tool

```python
import datetime, openai

def get_current_time():
    return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

functions = [
  {
    "name": "get_current_time",
    "description": "í˜„ì¬ ì‹œê°„ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜",
    "parameters": { "type": "object", "properties": {} }
  }
]

resp = openai.ChatCompletion.create(
    model="gpt-4o",
    messages=[{"role":"user","content":"ì§€ê¸ˆ ëª‡ ì‹œì•¼?"}],
    functions=functions,
    function_call="auto"
)
```

í´ë¼ì´ì–¸íŠ¸ê°€ `function_call`ì„ ê°ì§€í•˜ì—¬ ì‹¤ì œ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•œ ë’¤ ê²°ê³¼ë¥¼ GPTì— ì „ë‹¬í•´ ìµœì¢… ì‘ë‹µ ì™„ì„±.

---

## LangChain ê¸°ì´ˆ: LLMChain, ë©”ëª¨ë¦¬, í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

```python
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferWindowMemory
from langchain.chat_models import ChatOpenAI

conversation = ConversationChain(
    llm=ChatOpenAI(),
    memory=ConversationBufferWindowMemory(k=3)
)

print(conversation.predict(input="ì•ˆë…•?"))
print(conversation.predict(input="ë‚´ê°€ ë°©ê¸ˆ ë­ë¼ê³  í–ˆì§€?"))
```

### Output Parser ì˜ˆì‹œ (Pydantic)

```python
class QA(BaseModel):
    answer: str
    reason: str
parser = PydanticOutputParser(pydantic_object=QA)
prompt = PromptTemplate(
    template="Q: {question}\nA:",
    input_variables=["question"],
    partial_variables={"format_instructions": parser.get_format_instructions()}
)
chain = LLMChain(prompt=prompt, llm=ChatOpenAI(), output_parser=parser)
```

---

## LangChain ë„êµ¬ì™€ ì—ì´ì „íŠ¸: ê²€ìƒ‰ í†µí•©

```python
from langchain.tools import DuckDuckGoSearchRun
from langchain.agents import initialize_agent, AgentType
from langchain.chat_models import ChatOpenAI

search = DuckDuckGoSearchRun()
agent = initialize_agent(
    tools=[search],
    llm=ChatOpenAI(),
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)
agent.run("2025ë…„ ì›”ë“œì»µ ê°œìµœì§€ëŠ” ì–´ë””ì•¼?")
```

> **ì¸í„°ë„· ì°¨ë‹¨ ì‹œ:** DuckDuckGo ëŒ€ì‹  ì‚¬ë‚´ ê²€ìƒ‰ APIë¥¼ íˆ´ë¡œ ë“±ë¡.

---

## ë‚´ë¶€ ëª¨ë¸ê³¼ ë°ì´í„° í™œìš©: ë¡œì»¬ LLM ë° RAG

### ë¡œì»¬ LLM (Ollama)

```python
from langchain_ollama import ChatOllama
llm = ChatOllama(model="my-llama-model")
```

### RAG ê¸°ë³¸ íë¦„

```python
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

embed = HuggingFaceEmbeddings(model_name="BAAI/bge-small-ko-en")
db = FAISS.from_texts(docs, embedding=embed)
retriever = db.as_retriever(search_kwargs={"k": 5})

qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(),
    retriever=retriever
)
qa_chain.run("ì„œìš¸ 2040 ê³„íšì—ì„œ ì§€ì†ê°€ëŠ¥ì„± ì–¸ê¸‰ì´ ë‚˜ì˜¤ë‚˜ìš”?")
```

---

## ì¢…í•© í”„ë¡œì íŠ¸: ë©€í‹°ì—ì´ì „íŠ¸ ì±… ì‘ì„±

1. **Content Strategist**: ì±•í„°Â·ì„¹ì…˜ ê³„íš ìƒì„±  
2. **Research Agent**: ê´€ë ¨ ìë£Œ ê²€ìƒ‰  
3. **Communicator**: ë³¸ë¬¸ ì‘ì„±  
4. **Critic/Reviewer**: ë‚´ìš© ê²€í† Â·ìˆ˜ì •  
5. **Supervisor**: ì „ì²´ íë¦„ ê´€ë¦¬  

LangGraph ìŠ¤íƒ€ì¼ ì½”ë“œ(`book_writer.py`)ì—ì„œ íŒŒì´í”„(`|`) ì—°ì‚°ìë¡œ ì²´ì¸ ì—°ê²°.

---

## ê²°ë¡ 

- **ë©€í‹°ëª¨ë‹¬ ì…ë ¥(í…ìŠ¤íŠ¸Â·ìŒì„±Â·ì´ë¯¸ì§€)** ì²˜ë¦¬ â†’ LLM  
- **Function Calling / LangChain Tool**ë¡œ ì™¸ë¶€ ì •ë³´ í™œìš©  
- **ë¡œì»¬ LLM + RAG**ë¡œ ì‚¬ë‚´ ë°ì´í„° ì•ˆì „ í™œìš©  
- **ë©€í‹°ì—ì´ì „íŠ¸** í˜‘ì—…ìœ¼ë¡œ ë³µì¡í•œ ì‘ì—… ìë™í™”

LLM ê¸°ìˆ ì€ ë¹ ë¥´ê²Œ ì§„í™”í•©ë‹ˆë‹¤. ì‹¤ìŠµ ì½”ë“œ ì‹¤í–‰ â†’ í”„ë¡¬í”„íŠ¸ ìˆ˜ì • â†’ ê²°ê³¼ ë¹„êµ ê³¼ì •ì„ ë°˜ë³µí•˜ë©° **ì§ê´€ê³¼ ë…¸í•˜ìš°**ë¥¼ ìŒ“ì•„ê°€ì„¸ìš”. ğŸš€

<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NVIDIA Nsight 인터랙티브 분석 보고서</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Noto Sans KR', sans-serif;
        }
        /* Smooth scrolling for anchor links */
        html {
            scroll-behavior: smooth;
        }
        /* Custom styles for active tab */
        .tab-active {
            border-color: #10B981;
            background-color: #ECFDF5;
            color: #065F46;
            font-weight: 500;
        }
        /* Styles for tables */
        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 1.5rem;
            margin-bottom: 1.5rem;
        }
        th, td {
            border: 1px solid #e5e7eb;
            padding: 0.75rem;
            text-align: left;
        }
        th {
            background-color: #f9fafb;
            font-weight: 600;
        }
        tbody tr:nth-child(odd) {
            background-color: #f9fafb;
        }
        /* Style for subsections */
        .subsection {
            margin-top: 2.5rem;
            padding-top: 2rem;
            border-top: 1px solid #e5e7eb;
        }
        .subsection-title {
            font-size: 1.5rem;
            font-weight: 600;
            margin-bottom: 1rem;
            color: #111827;
        }
        .subsection-subtitle {
            font-size: 1.25rem;
            font-weight: 500;
            margin-top: 2rem;
            margin-bottom: 1rem;
            color: #1f2937;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid #f3f4f6;
        }
        .reference-link {
            color: #1D4ED8;
            font-weight: 500;
            text-decoration: none;
        }
        .reference-link:hover {
            text-decoration: underline;
        }
        .reference-item a {
            color: #059669;
            text-decoration: none;
        }
        .reference-item a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-800">

    <div class="container mx-auto p-4 sm:p-6 lg:p-8 max-w-7xl">
        <!-- Header -->
        <header class="mb-8 text-center">
            <h1 class="text-3xl sm:text-4xl font-bold text-gray-900">GPU 가속 데이터 사이언스를 위한 체계적 성능 최적화</h1>
            <p class="mt-2 text-lg text-gray-600">데이터 분석가를 위한 NVIDIA Nsight Suite 가이드</p>
        </header>

        <!-- Tab Navigation -->
        <div class="border-b border-gray-200 mb-8">
            <nav class="-mb-px flex space-x-4" aria-label="Tabs">
                <button onclick="changeTab(event, 'part1')" class="tab-btn tab-active whitespace-nowrap py-4 px-1 border-b-2 font-medium text-sm transition-colors duration-200">1부: 성능 프로파일링 환경</button>
                <button onclick="changeTab(event, 'part2')" class="tab-btn whitespace-nowrap py-4 px-1 border-b-2 border-transparent text-gray-500 hover:text-gray-700 hover:border-gray-300 font-medium text-sm transition-colors duration-200">2부: Nsight Systems</button>
                <button onclick="changeTab(event, 'part3')" class="tab-btn whitespace-nowrap py-4 px-1 border-b-2 border-transparent text-gray-500 hover:text-gray-700 hover:border-gray-300 font-medium text-sm transition-colors duration-200">3부: Nsight Compute</button>
                <button onclick="changeTab(event, 'part4')" class="tab-btn whitespace-nowrap py-4 px-1 border-b-2 border-transparent text-gray-500 hover:text-gray-700 hover:border-gray-300 font-medium text-sm transition-colors duration-200">4부: 결론 및 전략</button>
            </nav>
        </div>

        <!-- Tab Content -->
        <main>
            <!-- Part 1 Content -->
            <div id="part1" class="tab-content bg-white p-6 sm:p-8 rounded-lg shadow-sm">
                <div class="prose max-w-none">
                    <div class="subsection">
                        <h2 class="subsection-title">1.1. 서론: 통계 모델링에서 성능 공학으로</h2>
                        <p>현대 데이터 사이언스 분야에서 통계적 모델의 정확성과 타당성을 검증하는 것은 기본적인 절차입니다. 통계학자가 모델의 가정을 검증하듯, 계산 데이터 과학자는 코드의 성능 가정을 검증해야 합니다. 모델 훈련 시간, 추론 지연 시간, 그리고 계산 비용은 데이터 사이언스 프로젝트의 전반적인 "목표 함수"에서 중요한 변수들입니다.<a href="#ref1" class="reference-link">[1]</a> 성능 최적화는 더 이상 소수의 시스템 프로그래머에게만 국한된 전문 분야가 아니며, 대규모 데이터셋과 복잡한 모델을 다루는 모든 분석가에게 필수적인 역량이 되었습니다.</p>
                        <p>이러한 성능 분석 작업을 위해 구조화된 과학적 방법론이 필요하며, NVIDIA는 "APOD(Assess, Parallelize, Optimize, Deploy)" 프레임워크를 제시합니다.<a href="#ref2" class="reference-link">[2]</a> 이 프레임워크는 다음과 같은 체계적인 접근법을 제안합니다.</p>
                        <ol class="list-decimal list-inside space-y-2 my-4">
                            <li><strong>평가(Assess):</strong> 애플리케이션의 성능을 측정하고 병목 현상을 식별합니다.</li>
                            <li><strong>병렬화(Parallelize):</strong> CPU 및 GPU 리소스를 최대한 활용하도록 작업을 병렬화합니다.</li>
                            <li><strong>최적화(Optimize):</strong> 식별된 병목 현상을 해결하기 위해 코드를 수정하고 알고리즘을 개선합니다.</li>
                            <li><strong>배포(Deploy):</strong> 최적화된 애플리케이션을 실제 운영 환경에 배포합니다.</li>
                        </ol>
                        <p>이 보고서는 APOD 프레임워크를 기본 원칙으로 삼아, 데이터 분석가의 관점에서 NVIDIA Nsight 개발자 도구 모음을 활용하여 GPU 가속 애플리케이션의 성능을 체계적으로 분석하고 최적화하는 방법을 심층적으로 다룰 것입니다.</p>
                    </div>

                    <div class="subsection">
                        <h2 class="subsection-title">1.2. Nsight 에코시스템: 성능 분석을 위한 전문 도구 모음</h2>
                        <p>NVIDIA Nsight는 GPU를 활용하는 소프트웨어를 구축, 디버깅, 프로파일링 및 개발할 수 있도록 지원하는 강력한 라이브러리, SDK 및 개발자 도구 모음입니다.<a href="#ref3" class="reference-link">[3]</a> 이 에코시스템 내에서 데이터 분석가 및 머신러닝 엔지니어에게 가장 중요한 도구는 Nsight Systems와 Nsight Compute입니다.</p>
                        <ul class="list-disc list-inside space-y-3 my-4">
                            <li><strong>Nsight Systems:</strong> "매크로스코프(macroscope)" 또는 "시스템 전반 프로파일러(system-wide profiler)"로 비유할 수 있습니다. 이 도구의 주된 목적은 CPU, GPU, 메모리, 네트워크 I/O 등 시스템의 모든 구성 요소 간의 상호 작용을 시각화하여 거시적인 관점에서 병목 현상을 식별하는 것입니다.<a href="#ref4" class="reference-link">[4, 5, 6]</a> 모든 성능 분석 작업은 Nsight Systems에서 시작하는 것이 일반적입니다. 시스템 전체의 워크로드 메트릭을 통합된 타임라인에 시각화하여 개발자가 상관관계, 종속성, 병목 현상 및 리소스 할당을 조사할 수 있도록 지원합니다.<a href="#ref4" class="reference-link">[4]</a></li>
                            <li><strong>Nsight Compute:</strong> "마이크로스코프(microscope)" 또는 "대화형 커널 프로파일러(interactive kernel profiler)"로 설명할 수 있습니다. 이 도구의 목적은 Nsight Systems를 통해 문제가 있는 것으로 식별된 <em>단일</em> CUDA 커널에 대한 심층 분석을 수행하는 것입니다. 상세한 하드웨어 성능 메트릭을 제공하여 커널 수준의 비효율성을 파악하고 최적화하는 데 사용됩니다.<a href="#ref3" class="reference-link">[3, 6, 7]</a></li>
                            <li><strong>Nsight Graphics:</strong> 이 도구는 주로 Direct3D, Vulkan, OpenGL과 같은 그래픽 API를 사용하여 구축된 애플리케이션을 디버깅하고 프로파일링하는 데 사용됩니다.<a href="#ref3" class="reference-link">[3, 4, 8]</a> 데이터 시각화 요소가 중요한 역할을 하지 않는 한, 일반적인 계산 중심의 데이터 사이언스 워크로드에서는 주력으로 사용되지 않습니다.<a href="#ref9" class="reference-link">[9]</a></li>
                            <li><strong>기타 도구:</strong> 이 외에도 Nsight 에코시스템에는 IDE 통합을 위한 Nsight Visual Studio Edition(VSE)/Visual Studio Code Edition(VSCE), AI 기반 코딩 지원 도구인 Nsight Copilot, 그리고 JupyterLab 내에서 직접 프로파일링을 가능하게 하는 JupyterLab Extension 등 다양한 도구가 포함되어 있어 개발 생산성을 높여줍니다.<a href="#ref3" class="reference-link">[3, 10]</a></li>
                        </ul>
                    </div>
                    
                    <div class="subsection">
                        <h2 class="subsection-title">1.3. 기본 워크플로우: 거시적 분류에서 미시적 진단으로</h2>
                        <p>효율적이고 효과적인 최적화를 위해서는 NVIDIA가 의도적으로 설계한 2단계 워크플로우를 따르는 것이 중요합니다. 이 하향식 분석 워크플로우는 시스템 프로그래밍 전문가가 아닌 사용자도 조급한 마이크로 최적화의 함정에 빠지지 않도록 안내하는 교육적 설계의 핵심입니다. 이는 데이터 분석가가 전체 시스템을 먼저 이해하고 분산의 주요 원인을 식별한 후 세부 사항으로 파고드는 분석 프로세스와 완벽하게 일치합니다.</p>
                         <ul class="list-disc list-inside space-y-3 my-4">
                            <li><strong>1단계 (Nsight Systems):</strong> 시스템 전반의 트레이스를 수집하여 "애플리케이션의 알고리즘을 시각화"하고 "최적화를 위한 가장 큰 기회를 식별"하는 것으로 시작합니다.<a href="#ref4" class="reference-link">[4]</a> 이 단계의 목표는 "내 애플리케이션이 시간을 어디에 소비하고 있으며, GPU는 효과적으로 사용되고 있는가?"라는 질문에 답하는 것입니다.<a href="#ref6" class="reference-link">[6]</a> GPU 코드 성능 분석 프로세스는 일반적으로 Nsight Systems에서 시작되며, 분석을 통해 특정 커널에 초점을 맞춰 추가 분석을 진행할 수 있습니다.<a href="#ref11" class="reference-link">[11]</a></li>
                            <li><strong>2단계 (Nsight Compute):</strong> 시간이 많이 소요되는 특정 CUDA 커널이 병목 현상의 원인으로 지목되면, Nsight Compute를 사용하여 "GPU 성능을 심층적으로 분석"하고 "특정 CUDA 커널을 최적화"합니다.<a href="#ref6" class="reference-link">[6, 11]</a> 이 단계의 목표는 "이 특정 커널은 왜 느린가?"라는 질문에 답하는 것입니다.</li>
                        </ul>
                        <p>이러한 체계적인 접근법은 가장 큰 영향을 미치는 병목 현상을 데이터 기반으로 식별한 후에만 낮은 수준의 코드 변경에 시간을 투자하도록 유도합니다. 이는 한정된 자원과 시간을 가진 데이터 분석가에게 매우 효율적인 최적화 전략입니다.</p>
                    </div>
                </div>
            </div>

            <!-- Part 2 Content -->
            <div id="part2" class="tab-content hidden bg-white p-6 sm:p-8 rounded-lg shadow-sm">
                 <div class="prose max-w-none">
                    <div class="subsection">
                        <h2 class="subsection-title">2.1. 개념적 프레임워크: 시계열 분석으로서의 통합 타임라인</h2>
                        <p>Nsight Systems의 핵심은 모든 시스템 활동을 시간 순서대로 보여주는 <strong>타임라인 뷰(Timeline View)</strong>입니다.<a href="#ref1" class="reference-link">[1, 12]</a> 이 뷰는 단순한 차트가 아니라, 다변량 시계열 시각화로 해석할 수 있습니다.</p>
                        <ul class="list-disc list-inside space-y-2 my-4">
                            <li><strong>행(Rows)을 변수로:</strong> 타임라인의 각 행(예: CPU 코어, CUDA 스트림, NVTX 범위)은 시간에 따라 측정되는 개별 프로세스 또는 리소스를 나타냅니다.</li>
                            <li><strong>X축:</strong> 시간 축은 이벤트의 정확한 연대기적 기록을 제공합니다.</li>
                            <li><strong>이벤트를 데이터 포인트로:</strong> 타임라인에 표시되는 색상 블록(커널 실행, 메모리 복사, API 호출 등)은 개별 이벤트입니다. 이 블록 위에 마우스를 올리면 데이터 시각화의 툴팁처럼 지속 시간, 처리량 등 상세한 통계 요약을 볼 수 있습니다.<a href="#ref12" class="reference-link">[12]</a></li>
                        </ul>
                        <p>분석의 목표는 이러한 시계열 간의 상관관계와 종속성을 분석하여 성능 문제의 근본 원인을 찾는 것입니다. 예를 들어, CPU 행의 긴 막대(CPU 바운드 프로세스)가 GPU 행의 후속 공백(GPU 활동 부재)을 유발하는 인과 관계를 시각적으로 식별할 수 있습니다.<a href="#ref4" class="reference-link">[4]</a></p>
                    </div>

                    <div class="subsection">
                        <h2 class="subsection-title">2.2. Python 워크로드의 실제 프로파일링: 통찰력을 위한 계측</h2>
                        <h3 class="subsection-subtitle">2.2.1. NVTX(NVIDIA Tools Extension)의 필수적인 역할</h3>
                        <p>Python 스크립트의 원시 프로파일링 결과는 종종 해석하기 어려운 내부 CPython 호출의 연속으로 나타납니다. 이 문제를 해결하기 위해 NVTX는 Python 코드에서 직접 타임라인에 의미 있는, 사람이 읽을 수 있는 주석을 추가하는 방법을 제공합니다.<a href="#ref13" class="reference-link">[13]</a> NVTX는 데이터 과학자의 코드에 대한 멘탈 모델과 프로파일러가 캡처한 저수준 현실 사이의 다리 역할을 합니다. 이는 Python 기반 워크플로우에서 Nsight Systems를 유용하게 만드는 가장 중요한 단일 기술입니다.</p>
                        <p>NVTX는 <code>pip</code> 또는 <code>conda</code>를 통해 쉽게 설치할 수 있습니다.<a href="#ref14" class="reference-link">[14]</a></p>
                        <pre class="bg-gray-800 text-white p-4 rounded-md my-4 overflow-x-auto"><code>pip install nvtx</code></pre>
                        <p>NVTX를 사용하는 주된 두 가지 방법은 다음과 같습니다.</p>
                        <ul class="list-disc list-inside space-y-2 my-4">
                            <li><strong>데코레이터 (`@nvtx.annotate()`):</strong> 전체 함수를 표시하는 데 사용됩니다. 예를 들어, 훈련 에포크 함수 전체를 프로파일링할 때 유용합니다.<a href="#ref13" class="reference-link">[13, 14]</a></li>
                            <li><strong>컨텍스트 관리자 (`with nvtx.annotate(...)`):</strong> 함수 내의 특정 코드 블록(예: 루프, 데이터 로딩, 전방/후방 패스)을 표시하는 데 사용됩니다.<a href="#ref13" class="reference-link">[13, 14]</a></li>
                        </ul>
                        <pre class="bg-gray-800 text-white p-4 rounded-md my-4 overflow-x-auto"><code class="language-python">import nvtx
import time

@nvtx.annotate("train_epoch", color="purple")
def train_epoch(epoch_num):
    #... 훈련 로직...
    with nvtx.annotate("data_loading", color="blue"):
        time.sleep(0.1)
    with nvtx.annotate("forward_pass", color="green"):
        time.sleep(0.2)

train_epoch(1)</code></pre>
                        <p>PyTorch와 같은 주요 프레임워크는 <code>torch.cuda.nvtx.range_push/.range_pop</code> 또는 <code>with torch.autograd.profiler.emit_nvtx()</code>와 같은 내장 NVTX 래퍼를 제공하여 계측을 더욱 용이하게 합니다.<a href="#ref15" class="reference-link">[15, 16]</a> 프로파일링하지 않을 때 NVTX 호출의 오버헤드는 미미하므로, 프로덕션 코드에 남겨두어 필요시 온디맨드 프로파일링을 활성화할 수 있습니다.<a href="#ref13" class="reference-link">[13, 17]</a></p>

                        <h3 class="subsection-subtitle">2.2.2. 필수 `nsys` 명령줄 레시피</h3>
                        <p><code>nsys profile</code> 명령어는 Nsight Systems 프로파일링의 시작점입니다. 다음은 일반적인 사용 사례입니다.</p>
                        <ul class="list-disc list-inside space-y-3 my-4">
                            <li><strong>기본 명령어:</strong> <code class="bg-gray-100 p-1 rounded">nsys profile python my_script.py</code><br>이것은 시작점이지만 종종 필요한 세부 정보가 부족합니다.<a href="#ref18" class="reference-link">[18]</a></li>
                            <li><strong>GPU 워크로드 추적 추가:</strong> <code class="bg-gray-100 p-1 rounded">nsys profile -t cuda,nvtx,osrt,cudnn,cublas python my_script.py</code><br>이 명령어는 다양한 API와 라이브러리 호출을 추적합니다. 각 플래그의 의미는 다음과 같습니다.<a href="#ref15" class="reference-link">[15, 19]</a>
                                <ul class="list-circle list-inside ml-6 mt-2 space-y-1">
                                    <li><code>cuda</code>: CUDA API 호출</li>
                                    <li><code>nvtx</code>: NVTX 사용자 정의 주석</li>
                                    <li><code>osrt</code>: 운영 체제 런타임 호출 (예: <code>sleep</code>, <code>read</code>)</li>
                                    <li><code>cudnn</code>, <code>cublas</code>: 딥러닝 및 선형대수 라이브러리 호출</li>
                                </ul>
                            </li>
                            <li><strong>오버헤드 및 초점 관리:</strong>
                                <ul class="list-circle list-inside ml-6 mt-2 space-y-1">
                                    <li><strong>CPU 샘플링 (`-s`):</strong> 이 옵션은 트레이드오프를 가집니다. <code>-s none</code>은 가장 낮은 오버헤드로 이벤트의 정확한 타임라인을 제공합니다. <code>-s cpu</code>는 CPU 백트레이스를 수집하여 CPU 바운드 코드를 디버깅하는 데 강력하지만 상당한 오버헤드를 추가할 수 있습니다.<a href="#ref19" class="reference-link">[19]</a></li>
                                    <li><strong>집중 프로파일링 (`--capture-range`):</strong> 코드 내에서 <code>cudaProfilerStart()</code>/<code>Stop()</code> API(예: PyTorch의 <code>torch.cuda.profiler.start()</code>)를 호출하고, 이를 <code>--capture-range=cudaProfilerApi --stop-on-range-end=true</code> 옵션과 함께 사용하면 코드의 특정 "핫스팟" 영역만 프로파일링할 수 있습니다. 이는 장시간 실행되는 훈련 작업에서 보고서 파일 크기와 분석 복잡성을 줄이는 데 매우 중요합니다.<a href="#ref16" class="reference-link">[16, 19]</a></li>
                                </ul>
                            </li>
                            <li><strong>PyTorch를 위한 "최적의" 시작 명령어:</strong><br>다음은 일반적인 PyTorch 스크립트에 대한 강력한 시작 명령어로, 여러 정보 소스에서 종합한 것입니다.<a href="#ref19" class="reference-link">[19]</a>
                                <pre class="bg-gray-800 text-white p-4 rounded-md my-4 overflow-x-auto"><code>nsys profile -w true -t cuda,nvtx,osrt,cudnn,cublas -s cpu --cudabacktrace=true -o my_pytorch_profile -f true python train.py</code></pre>
                                <ul class="list-circle list-inside ml-6 mt-2 space-y-1">
                                    <li><code>-w true</code>: 애플리케이션의 콘솔 출력을 유지합니다.</li>
                                    <li><code>--cudabacktrace=true</code>: 특정 임계값을 초과하는 CUDA API 호출에 대한 CPU 스택 샘플을 수집합니다.</li>
                                    <li><code>-o my_pytorch_profile</code>: 출력 파일 이름을 지정합니다.</li>
                                    <li><code>-f true</code>: 기존 출력 파일을 덮어씁니다.</li>
                                </ul>
                            </li>
                            <li><strong>다중 노드/프로세스 프로파일링:</strong> Nsight Systems는 분산 훈련 환경도 지원하며, 여러 노드의 데이터를 자동으로 수집하고 상호 연관시킬 수 있습니다.<a href="#ref20" class="reference-link">[20, 21]</a></li>
                        </ul>

                        <h3 class="subsection-subtitle">2.2.3. JupyterLab에서의 대화형 분석</h3>
                        <p>데이터 과학자들은 주로 Jupyter 노트북 환경에서 작업합니다. Nsight Tools JupyterLab Extension은 이러한 워크플로우에 프로파일링을 원활하게 통합합니다.<a href="#ref3" class="reference-link">[3, 10, 22]</a> 이 확장을 사용하면 개발 환경을 벗어나지 않고도 개별 셀의 실행에 대한 상세한 성능 분석을 수행할 수 있어 반복적인 최적화 프로세스를 크게 간소화할 수 있습니다.</p>
                    </div>

                    <div class="subsection">
                        <h2 class="subsection-title">2.3. 타임라인 해석: 시각적 진단을 위한 데이터 분석가 가이드</h2>
                        <p>Nsight Systems 타임라인을 "읽고" 일반적인 성능 안티패턴을 식별하는 방법을 배우는 것은 매우 중요합니다.</p>
                        <figure class="my-6">
                            <img src="https://raw.githubusercontent.com/regpath/regpath.github.io/main/AI/Nvidia-nsight/cuda-image-3.png" alt="Nsight Systems 타임라인 뷰 예시" class="w-full h-auto rounded-lg shadow-md border">
                            <figcaption class="text-center text-sm text-gray-500 mt-2">Nsight Systems 타임라인 뷰는 시스템의 모든 활동을 시계열로 보여줍니다.</figcaption>
                        </figure>
                        <ul class="list-disc list-inside space-y-2 my-4">
                            <li><strong>GPU 기아 상태 (CPU-Bound):</strong> 가장 흔한 문제입니다. CPU 행에 긴 수평 막대가 나타나고, 그 뒤를 이어 GPU 행에 큰 공백이 생기는 것이 특징입니다. 이는 GPU가 CPU로부터 데이터를 기다리고 있음을 시각적으로 증명합니다. 이 패턴은 주로 데이터 로딩 및 전처리 병목 현상과 관련이 있습니다.<a href="#ref1" class="reference-link">[1, 23]</a></li>
                            <li><strong>메모리 전송 병목 현상:</strong> "CUDA Memory" 행(예: 호스트에서 디바이스로의 복사를 의미하는 <code>HtoD</code>)에서 상당한 시간이 소요되는 것으로 식별됩니다. 툴팁에 제공되는 PCIe 처리량 메트릭을 분석하고<a href="#ref12" class="reference-link">[12]</a>, <code>pin_memory</code>와 같은 최적화를 고려해야 할 시점을 판단할 수 있습니다.<a href="#ref1" class="reference-link">[1]</a></li>
                            <li><strong>커널 실행 오버헤드:</strong> 매우 작은 커널 실행이 눈에 띄는 간격을 두고 연속적으로 나타나는 것으로, 각 커널을 개별적으로 실행하는 데 따르는 CPU 오버헤드가 상당함을 나타냅니다. 이는 CUDA Graphs가 해결하는 주요 문제입니다.<a href="#ref23" class="reference-link">[23]</a></li>
                            <li><strong>부실한 CPU/GPU 동시성:</strong> 이상적인 시나리오는 GPU가 현재 배치를 처리하는 동안 CPU가 다음 데이터 배치를 준비하는 것입니다. 타임라인은 이러한 작업이 병렬이 아닌 직렬로 실행되는지 여부를 쉽게 보여줍니다.</li>
                        </ul>
                        <p class="font-semibold mt-6 mb-2">표 2.1: 일반적인 Nsight Systems 타임라인 패턴과 데이터 분석가를 위한 시사점</p>
                        <div class="overflow-x-auto">
                            <table>
                                <thead>
                                    <tr>
                                        <th>시각적 패턴 (Visual Pattern)</th>
                                        <th>유력한 원인 (Probable Cause)</th>
                                        <th>확인할 주요 지표 (Key Indicators to Check)</th>
                                        <th>데이터 과학자를 위한 첫 단계 (First Steps for a Data Scientist)</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td><strong>GPU 행의 넓은 공백, CPU 행의 높은 활동</strong></td>
                                        <td>GPU 기아 상태 / CPU 바운드 데이터 전처리</td>
                                        <td>CPU 행의 높은 사용률; GPU HW 행의 낮은 사용률; 데이터 로딩 관련 NVTX 범위의 긴 지속 시간</td>
                                        <td>PyTorch <code>DataLoader</code>에서 <code>num_workers</code> 증가; <code>pin_memory=True</code> 설정; 데이터 사전 인출(pre-fetching) 전략 검토</td>
                                    </tr>
                                    <tr>
                                        <td><strong><code>CUDA Memory</code> 행의 긴 막대</strong></td>
                                        <td>비효율적인 호스트-디바이스 메모리 복사</td>
                                        <td>PCIe 처리량이 이론적 최대치보다 현저히 낮음; 훈련 루프 내에서 반복적인 작은 데이터 전송</td>
                                        <td><code>pin_memory=True</code>를 사용하여 고정 메모리 사용; 데이터 전송을 비동기화 (<code>non_blocking=True</code>); 여러 개의 작은 전송을 하나의 큰 전송으로 묶기</td>
                                    </tr>
                                    <tr>
                                        <td><strong>작은 GPU 커널들 사이의 명확한 간격</strong></td>
                                        <td>높은 커널 실행 오버헤드</td>
                                        <td>개별 커널의 실행 시간은 매우 짧지만, 커널 사이의 유휴 시간이 김; CPU가 100% 사용률을 보임</td>
                                        <td>CUDA Graphs를 사용하여 여러 커널 실행을 하나의 작업으로 묶어 CPU 오버헤드 제거 (PyTorch 1.10+ 지원)</td>
                                    </tr>
                                    <tr>
                                        <td><strong>CPU와 GPU 작업의 직렬 실행</strong></td>
                                        <td>부실한 동시성 / 스트림 부족</td>
                                        <td>타임라인에서 CPU 작업(데이터 준비)과 GPU 작업(계산)이 겹치지 않고 순차적으로 발생함</td>
                                        <td>CUDA 스트림을 사용하여 데이터 전송과 계산을 중첩(overlap)시켜 파이프라인 효율성 증대</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <div class="subsection">
                        <h2 class="subsection-title">2.4. 사례 연구: Nsight Systems를 이용한 딥러닝 병목 현상 해결</h2>
                        <p>Microsoft의 기사에서 제시된 최적화 사례는 Nsight Systems를 사용한 전체적인 평가 -> 가설 수립 -> 최적화 -> 재평가 과정을 명확하게 보여줍니다.<a href="#ref1" class="reference-link">[1]</a></p>
                        <ul class="list-disc list-inside space-y-3 my-4">
                            <li><strong>기준선(Baseline):</strong> 초기 코드를 프로파일링합니다. Nsight Systems 보고서는 28초의 실행 시간, 막대한 CPU 대기 시간, 그리고 제대로 활용되지 않는 GPU를 보여줍니다. 타임라인은 작은 CUDA 연산 후 긴 CPU 대기 시간으로 특징지어지며, 이는 GPU 계산이 아닌 데이터 처리에서 병목이 발생하고 있음을 시사합니다.</li>
                            <li><strong>가설 1 및 수정 1:</strong> 병목 현상은 데이터 로딩에 있습니다. <code>DataLoader</code>에서 <code>num_workers</code>를 CPU 코어 수와 같게 설정하는 코드 변경을 적용합니다.<br><code class="bg-gray-100 p-1 rounded">num_workers = os.cpu_count()</code></li>
                            <li><strong>분석 1:</strong> 다시 프로파일링합니다. 새로운 보고서는 실행 시간이 약 3.1초로 극적으로 감소하고 GPU 활용률이 크게 향상되었음을 보여줍니다. 이제 GPU는 데이터를 기다리는 대신 계산에 더 많은 시간을 소비합니다.</li>
                            <li><strong>가설 2 및 수정 2:</strong> 프로세스 포크(fork)와 동기식 메모리 복사로 인한 비효율성이 여전히 남아 있습니다. Nsight Systems 시각 자료는 NVTX 범위가 트리거된 시점과 코드 실행이 시작되는 시점 사이에 상당한 지연이 있음을 보여주는데, 이는 많은 포크 연산 때문입니다. 이를 해결하기 위해 다음과 같은 코드 변경을 적용합니다.
                                <ul class="list-circle list-inside ml-6 mt-2 space-y-1">
                                    <li><code>pin_memory=True</code>: 호스트-디바이스 간 데이터 전송 속도를 높입니다.</li>
                                    <li><code>persistent_workers=True</code>: 훈련 중 포크 연산 수를 줄여 워커 프로세스 생성 오버헤드를 감소시킵니다.</li>
                                    <li><code>data.cuda(non_blocking=True)</code>: CPU에서 GPU로의 데이터 전송을 비동기화합니다.</li>
                                </ul>
                            </li>
                            <li><strong>분석 2:</strong> 최종 프로파일링을 수행합니다. 보고서는 실행 시간이 약 2.2초로 더욱 단축되었으며(총 92.9% 개선), 커널들이 촘촘하게 채워져 있고 NVTX 타임라인이 명확해졌음을 보여줍니다. CUDA 커널 실행에 시간의 93%가 소요되고 메모리 전송에는 7.8%만 소요되어, CUDA 연산에 대한 효과적인 활용을 나타냅니다.</li>
                        </ul>
                        <p>이 단계별 서술은 Nsight Systems를 사용하여 성능 문제를 진단하고 해결하는 전체 과정을 구체적으로 보여줌으로써 사용자의 이해를 돕습니다.</p>
                    </div>
                 </div>
            </div>

            <!-- Part 3 Content -->
            <div id="part3" class="tab-content hidden bg-white p-6 sm:p-8 rounded-lg shadow-sm">
                <div class="prose max-w-none">
                    <div class="subsection">
                        <h2 class="subsection-title">3.1. 개념적 프레임워크: 통계 시스템으로서의 커널</h2>
                        <p>Nsight Systems가 <em>어떤</em> 커널을 조사해야 하는지 알려주었다면, Nsight Compute는 그 커널을 분석하는 도구입니다.<a href="#ref6" class="reference-link">[6, 11]</a> 커널 분석은 통계적 문제로 접근할 수 있습니다. 하나의 커널 실행은 수백만 개의 스레드, 명령어, 메모리 접근을 포함합니다. Nsight Compute의 역할은 이 이벤트 모집단에서 성능 카운터와 샘플을 수집하고, 근본적인 성능 특성을 드러내는 통계적 요약을 제시하는 것입니다.</p>
                        <p>프로파일링 프로세스는 다음과 같이 진행됩니다: 도구는 커널 실행을 가로채고, 오버헤드를 줄이기 위해 커널을 여러 번 다시 실행하여 각기 다른 메트릭 세트를 수집한 다음, 그 결과를 단일 보고서로 집계합니다.<a href="#ref24" class="reference-link">[24]</a></p>
                    </div>

                    <div class="subsection">
                        <h2 class="subsection-title">3.2. 데이터 분석가의 대시보드: 주요 메트릭 섹션 해석</h2>
                        <p>이 섹션에서는 Nsight Compute 보고서의 주요 섹션을 탐색하며, 하드웨어 개념을 데이터 분석가가 이해할 수 있는 용어로 변환합니다. 이는 프로파일링 가이드의 상세한 설명을 기반으로 합니다.<a href="#ref24" class="reference-link">[24]</a></p>
                        
                        <h3 class="subsection-subtitle">3.2.1. GPU Speed of Light</h3>
                        <p>이 섹션은 커널의 성능이 계산 및 메모리 대역폭 측면에서 하드웨어의 이론적 최대 성능과 어떻게 비교되는지를 보여주는 최상위 요약입니다. 이는 개선의 여지가 얼마나 있는지를 즉각적으로 파악하게 해줍니다.</p>

                        <h3 class="subsection-subtitle">3.2.2. 메모리 워크로드 분석 (Memory Workload Analysis)</h3>
                        <ul class="list-disc list-inside space-y-2 my-4">
                            <li><strong>핵심 개념:</strong> 커널의 성능이 데이터를 얼마나 빨리 가져올 수 있는지에 의해 제한되는가? <a href="#ref7" class="reference-link">[7, 24]</a></li>
                            <li><strong>주요 메트릭:</strong>
                                <ul class="list-circle list-inside ml-6 mt-2 space-y-1">
                                    <li><strong>L1/L2 캐시 적중률(Cache Hit Rate):</strong> 요청된 데이터가 캐시에서 발견될 확률입니다.</li>
                                    <li><strong>메모리 대역폭 활용률(Memory Bandwidth Utilization):</strong> 이론적인 최대 데이터 전송률의 몇 퍼센트를 달성하고 있는지를 나타냅니다.</li>
                                    <li><strong>메모리 트래픽 분석:</strong> 서로 다른 메모리 유형(전역, 공유, 로컬) 간의 트래픽 분석을 제공합니다.<a href="#ref24" class="reference-link">[24]</a></li>
                                </ul>
                            </li>
                            <li><strong>데이터 분석가를 위한 의미:</strong> 낮은 L2 캐시 적중률은 알고리즘의 데이터 지역성(data locality)이 좋지 않음을 시사합니다. 높은 메모리 대역폭 활용률은 커널이 "메모리 바운드(memory-bound)" 상태임을 의미하며, 로드된 데이터 바이트당 더 많은 계산을 수행하는 알고리즘 변경이 도움이 될 수 있습니다.</li>
                        </ul>

                        <h3 class="subsection-subtitle">3.2.3. 스케줄러 및 워프 상태 통계 (Scheduler and Warp State Statistics)</h3>
                        <ul class="list-disc list-inside space-y-2 my-4">
                            <li><strong>핵심 개념:</strong> 커널의 성능이 명령어를 얼마나 빨리 실행할 수 있는지에 의해 제한되는가, 아니면 무언가를 기다리느라 지연되는가? <a href="#ref24" class="reference-link">[24]</a></li>
                            <li><strong>주요 메트릭:</strong> <strong>워프 지연 이유(Warp Stall Reasons)</strong>의 분포를 분석합니다. 이는 워프가 실행될 수 없었던 이유를 보여주는 히스토그램입니다. 주요 지연 이유는 다음과 같습니다.
                                <ul class="list-circle list-inside ml-6 mt-2 space-y-1">
                                    <li><code>Long Scoreboard</code>: 메모리 연산이 완료되기를 기다리며 지연되었습니다. 이 비율이 높으면 메모리 바운드 커널이라는 강력한 통계적 증거가 됩니다.</li>
                                    <li><code>Barrier</code>: 동일한 스레드 블록 내의 다른 워프가 동기화되기를 기다리며 지연되었습니다. 이는 스레드 블록 내의 작업량 불균형을 나타낼 수 있습니다.</li>
                                    <li><code>Not Selected</code>: 워프는 실행 준비가 되었지만 다른 워프가 대신 선택되었습니다. 이 비율이 높은 것은 지연 시간을 숨길 만큼 충분한 병렬성이 있다는 <em>좋은</em> 신호일 수 있습니다.</li>
                                </ul>
                            </li>
                            <li><strong>데이터 분석가를 위한 의미:</strong> 이 섹션은 모든 워프에게 "무엇을 기다리고 있었습니까?"라고 묻는 설문조사와 같습니다. 결과 분포는 커널의 주요 제한 요인을 분류하는 강력한 진단 도구입니다.</li>
                        </ul>

                        <h3 class="subsection-subtitle">3.2.4. 소스 코드 상관관계 (Source Code Correlation)</h3>
                        <p>이 섹션은 Nsight Compute의 "Source" 페이지를 설명하며, 이는 코드와의 궁극적인 연결 고리입니다.<a href="#ref7" class="reference-link">[7, 25]</a> 캐시 미스나 지연된 명령어와 같은 성능 메트릭을 CUDA C++, PTX 또는 SASS 어셈블리 코드의 개별 라인에 직접 귀속시켜 보여줍니다. "히트맵" 기능은 가장 "핫(hot)"하거나 비용이 많이 드는 코드 라인을 시각적으로 강조합니다.<a href="#ref7" class="reference-link">[7]</a> Numba나 RAPIDS와 같은 라이브러리를 사용하는 데이터 과학자에게 이 뷰는 생성된 CUDA 코드를 보여주어 고수준 Python 코드가 어떻게 변환되는지에 대한 통찰력을 제공할 수 있습니다.</p>
                        <figure class="my-6">
                            <img src="https://raw.githubusercontent.com/regpath/regpath.github.io/main/AI/Nvidia-nsight/nsight-compute-correlate-source-code-630x354.jpg" alt="Nsight Compute 소스 코드 뷰" class="w-full h-auto rounded-lg shadow-md border max-w-2xl mx-auto">
                            <figcaption class="text-center text-sm text-gray-500 mt-2">Nsight Compute의 소스 코드 뷰. 코드 라인 옆에 히트맵이 표시되어 어떤 코드 라인이 가장 많은 리소스를 소비하는지 시각적으로 강조합니다.</figcaption>
                        </figure>
                        <p class="font-semibold mt-6 mb-2">표 3.1: 주요 Nsight Compute 메트릭과 데이터 과학자를 위한 의미</p>
                        <div class="overflow-x-auto">
                           <table>
                                <thead>
                                    <tr>
                                        <th>메트릭/섹션 (Metric/Section)</th>
                                        <th>평이한 정의 (Plain Language Definition)</th>
                                        <th>'나쁜' 값의 형태 (What a 'Bad' Value Looks Like)</th>
                                        <th>데이터 과학자를 위한 시사점 (Implications for a Data Scientist)</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td><strong>GPU Speed of Light -> SM/Memory Throughput</strong></td>
                                        <td>커널이 스트리밍 멀티프로세서(SM)의 계산 능력과 메모리 대역폭을 이론적 최대치 대비 얼마나 활용했는지</td>
                                        <td>두 값 모두 낮은 백분율 (예: 30% 미만)</td>
                                        <td>커널이 하드웨어 리소스를 제대로 활용하지 못하고 있음. 지연 시간 병목 현상일 가능성이 높음.</td>
                                    </tr>
                                    <tr>
                                        <td><strong>Memory Workload Analysis -> L2 Hit Rate</strong></td>
                                        <td>메모리 요청이 GPU의 L2 캐시에서 성공적으로 발견된 비율</td>
                                        <td>낮은 백분율 (예: 50-60% 미만)</td>
                                        <td>알고리즘의 데이터 지역성이 좋지 않음. 스레드들이 메모리상에서 멀리 떨어진 데이터에 접근하여 VRAM으로의 느린 접근이 빈번함. 데이터 구조나 알고리즘을 재구성하여 공간적/시간적 재사용성을 높이는 것을 고려.</td>
                                    </tr>
                                    <tr>
                                        <td><strong>Scheduler Statistics -> Warp Stall Reason: Long Scoreboard</strong></td>
                                        <td>워프가 메모리(전역 또는 로컬) 읽기/쓰기 작업이 완료되기를 기다리며 지연된 비율</td>
                                        <td>높은 백분율 (예: 30-40% 이상)</td>
                                        <td>커널이 메모리 지연 시간에 의해 심각하게 제한됨(메모리 바운드). 캐시 효율성을 높이거나, 필요한 데이터 양을 줄이거나, 계산 강도(연산/바이트)를 높이는 알고리즘 변경이 필요함.</td>
                                    </tr>
                                    <tr>
                                        <td><strong>Scheduler Statistics -> Warp Stall Reason: Barrier</strong></td>
                                        <td>워프가 <code>__syncthreads()</code>와 같은 배리어에서 다른 워프들을 기다리며 지연된 비율</td>
                                        <td>높은 백분율</td>
                                        <td>스레드 블록 내 워프 간 작업량 불균형. 일부 워프가 다른 워프보다 훨씬 일찍 배리어에 도달함. 블록 내 스레드에 작업을 분배하는 방식을 재고하여 부하를 균등하게 만들어야 함.</td>
                                    </tr>
                                    <tr>
                                        <td><strong>Source Page -> SASS Instructions/Line</strong></td>
                                        <td>소스 코드 한 라인에 대해 생성된 저수준 SASS(어셈블리) 명령어의 수</td>
                                        <td>특정 라인에 대해 비정상적으로 많은 명령어 수</td>
                                        <td>컴파일러가 해당 고수준 코드를 매우 비효율적으로 번역했을 수 있음. 코드를 더 간단한 연산으로 나누거나 다른 방식으로 표현하여 컴파일러 최적화를 유도하는 것을 고려.</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <div class="subsection">
                        <h2 class="subsection-title">3.3. 유도 분석 및 반복적 최적화</h2>
                        <p>Nsight Compute는 전문가가 아닌 사용자를 돕기 위한 기능들을 제공합니다.</p>
                        <ul class="list-disc list-inside space-y-2 my-4">
                            <li><strong>규칙 엔진(Rules Engine):</strong> Nsight Compute에는 수집된 데이터를 자동으로 분석하고 잠재적인 문제를 평문 설명 및 관련 문서 링크와 함께 알려주는 전문가 시스템이 내장되어 있습니다.<a href="#ref7" class="reference-link">[7, 25, 26]</a> 이는 "자동화된 통계 분석"의 한 형태로, 일차적인 진단을 제공합니다.</li>
                            <li><strong>기준선 기능(Baseline Feature):</strong> 코드 변경 후 다시 프로파일링하고 새로운 보고서를 이전 보고서와 직접 비교할 수 있습니다. 이 도구는 모든 메트릭 차이를 강조 표시하여 변경 사항이 성능에 도움이 되었는지 아니면 해가 되었는지에 대한 정량적 증거를 제공합니다.<a href="#ref7" class="reference-link">[7, 27]</a> 이는 엄격하고 과학적인 최적화 접근법을 강제합니다.</li>
                        </ul>
                    </div>

                    <div class="subsection">
                        <h2 class="subsection-title">3.4. 사례 연구: CUDA Graphs를 이용한 커널 성능 해부</h2>
                        <p>이 사례 연구는 2부에서 소개된 CUDA Graphs 개념을 기반으로 합니다.</p>
                        <figure class="my-6">
                            <img src="https://raw.githubusercontent.com/regpath/regpath.github.io/main/AI/Nvidia-nsight/cuda-image-2.png" alt="CUDA Graphs 적용 전후 비교" class="w-full h-auto rounded-lg shadow-md border">
                            <figcaption class="text-center text-sm text-gray-500 mt-2">CUDA Graphs 적용 전(위)과 후(아래)의 Nsight Systems 타임라인 비교. 그래프 적용 후 커널 실행 오버헤드가 사라지고 커널들이 촘촘하게 채워진 것을 볼 수 있습니다.</figcaption>
                        </figure>
                        <ul class="list-disc list-inside space-y-3 my-4">
                            <li><strong>1단계 (Nsight Systems):</strong> Nsight Systems를 사용하여 CUDA Graphs가 있는 경우와 없는 경우의 PyTorch 모델을 분석합니다. "이전" 트레이스는 높은 실행 오버헤드의 특징적인 간격을 보여줍니다. "이후" 트레이스는 단일 그래프 실행 내에 촘촘하게 채워진 커널들을 보여주어 시스템 수준의 이점을 입증합니다.<a href="#ref23" class="reference-link">[23]</a></li>
                            <li><strong>2단계 (Nsight Compute):</strong> 이제 새로운 질문을 던집니다: "커널을 그래프로 래핑하는 것이 개별 성능을 변경했는가?" Nsight Compute를 사용하여 그래프 <em>내에서</em> 주요 커널 중 하나(예: 대규모 행렬 곱셈)를 프로파일링합니다.</li>
                            <li><strong>분석:</strong> 이 커널에 대한 Nsight Compute 보고서를 분석하여 메모리 워크로드와 스케줄러 통계를 살펴봅니다. 목표는 커널이 여전히 효율적인지(예: 높은 계산 활용률, 우수한 지연 시간 숨김) 확인하는 것입니다. 이는 전체적인 매크로-마이크로 워크플로우를 보여주며, 두 도구가 어떻게 상호 보완하여 완벽한 성능 그림을 제공하는지를 보여줍니다.</li>
                        </ul>
                    </div>
                </div>
            </div>

            <!-- Part 4 Content -->
            <div id="part4" class="tab-content hidden bg-white p-6 sm:p-8 rounded-lg shadow-sm">
                <div class="prose max-w-none">
                    <div class="subsection">
                        <h2 class="subsection-title">4.1. 종합: 데이터 기반 최적화 루프</h2>
                        <p>이 보고서의 핵심 내용을 요약하면, 데이터 기반 최적화는 다음과 같은 반복적인 루프로 구성됩니다.</p>
                        <ol class="list-decimal list-inside space-y-2 my-4 bg-green-50 p-6 rounded-lg border border-green-200">
                            <li><strong>계측(Instrument):</strong> Python 코드에 NVTX 범위를 추가합니다.</li>
                            <li><strong>분류(Triage, Nsight Systems):</strong> 시스템 전반의 프로파일링을 실행하여 가장 큰 병목 현상을 찾습니다. 원인이 CPU, 메모리 복사, 아니면 특정 GPU 커널인지 파악합니다.</li>
                            <li><strong>진단(Diagnose, Nsight Compute):</strong> 원인이 커널이라면 심층 프로파일링을 실행합니다. 메트릭 테이블과 유도 분석을 사용하여 <em>왜</em> 느린지(메모리 바운드, 계산 바운드, 지연 시간 바운드) 이해합니다.</li>
                            <li><strong>최적화(Optimize):</strong> 진단에 기반하여 목표에 맞는 코드 또는 알고리즘 변경을 수행합니다.</li>
                            <li><strong>검증(Validate, Baselining):</strong> 다시 프로파일링하고 기준선과 비교하여 변경이 효과적이었음을 증명합니다.</li>
                            <li><strong>반복:</strong> 만족스러운 성능에 도달할 때까지 이 과정을 반복합니다.</li>
                        </ol>
                    </div>

                    <div class="subsection">
                        <h2 class="subsection-title">4.2. 데이터 분석가를 위한 사전 예방적 성능 튜닝 체크리스트</h2>
                        <p>이러한 관행을 표준 데이터 사이언스 프로젝트에 통합하기 위한 실행 가능한 권장 사항 목록은 다음과 같습니다.</p>
                        <ul class="list-disc list-inside space-y-3 my-4">
                            <li><strong>개발 중:</strong> 항상 <code>DataLoader</code> 모범 사례(<code>num_workers</code>, <code>pin_memory</code>)를 사용합니다.</li>
                            <li><strong>초기 모델 실행 중:</strong> 빠른 Nsight Systems 트레이스를 실행하여 명백한 GPU 기아 상태를 확인합니다.</li>
                            <li><strong>대규모 훈련 전:</strong> 몇 번의 반복에 대해 집중 프로파일링을 수행하여 상당한 계산 예산을 지출하기 전에 파이프라인이 효율적인지 확인합니다.</li>
                            <li><strong>규모 확장 시:</strong> Nsight Systems의 다중 노드 기능을 사용하여 분산 훈련 성능을 분석합니다.</li>
                        </ul>
                        <p class="mt-6 p-4 bg-blue-50 border-l-4 border-blue-500 rounded-r-lg">궁극적인 목표는 독자의 사고방식을, 성능이 느릴 때 사용하는 사후 대응적 디버깅 도구에서 처음부터 효율성을 보장하기 위한 사전 예방적 실천으로 전환하는 것입니다. 체계적인 프로파일링과 분석을 통해 데이터 과학자는 모델의 통계적 성능뿐만 아니라 계산적 성능도 최적화하여 더 빠르고 비용 효율적인 결과를 얻을 수 있습니다.</p>
                    </div>
                </div>
            </div>
        </main>

        <!-- References Section -->
        <footer id="references" class="mt-12 pt-8 border-t-2 border-gray-200">
            <h2 class="text-2xl font-bold text-gray-800 mb-6">참고문헌</h2>
            <ol class="list-decimal list-inside space-y-4 text-gray-700">
                <li id="ref1" class="reference-item">A. Sharma, "End-to-end GPU-accelerated data science workflow for deep learning in PyTorch," Microsoft, 2023. <a href="https://techcommunity.microsoft.com/t5/educator-developer-blog/end-to-end-gpu-accelerated-data-science-workflow-for-deep/ba-p/3982292" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref2" class="reference-item">NVIDIA, "APOD (Assess, Parallelize, Optimize, and Deploy) Cycle," NVIDIA Developer. <a href="https://www.nvidia.com/en-us/industries/aerospace-defense/apod/" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref3" class="reference-item">NVIDIA, "NVIDIA Nsight Developer Tools," NVIDIA Developer. <a href="https://developer.nvidia.com/nsight-developer-tools" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref4" class="reference-item">NVIDIA, "NVIDIA Nsight Systems," NVIDIA Developer. <a href="https://developer.nvidia.com/nsight-systems" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref5" class="reference-item">J. Kim, "NVIDIA Nsight System으로 GPU 성능 분석하기," 2022. <a href="https://www.42maru.com/ko/blog/nvidia-nsight-system%EC%9C%BC%EB%A1%9C-gpu-%EC%84%B1%EB%8A%A5-%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0/" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref6" class="reference-item">NVIDIA, "Nsight Systems and Nsight Compute," NVIDIA On-Demand. <a href="https://www.nvidia.com/en-us/on-demand/session/gtcfall21-a31553/" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref7" class="reference-item">NVIDIA, "NVIDIA Nsight Compute," NVIDIA Developer. <a href="https://developer.nvidia.com/nsight-compute" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref8" class="reference-item">NVIDIA, "NVIDIA Nsight Graphics," NVIDIA Developer. <a href="https://developer.nvidia.com/nsight-graphics" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref9" class="reference-item">NVIDIA, "Nsight Tools for Ray Tracing," NVIDIA On-Demand. <a href="https://www.nvidia.com/en-us/on-demand/session/gtcspring21-s31331/" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref10" class="reference-item">NVIDIA, "NVIDIA Nsight Visual Studio Code Edition," NVIDIA Developer. <a href="https://developer.nvidia.com/nsight-visual-studio-code-edition" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref11" class="reference-item">NVIDIA, "Using Nsight Systems and Nsight Compute," NVIDIA Developer. <a href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html#using-nsight-systems-and-nsight-compute" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref12" class="reference-item">NVIDIA, "Nsight Systems GUI," NVIDIA Developer. <a href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html#gui" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref13" class="reference-item">NVIDIA, "Annotating Code with NVTX," NVIDIA Developer. <a href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html#annotating-code-with-nvtx" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref14" class="reference-item">NVIDIA, "NVTX-Plugins," GitHub. <a href="https://github.com/NVIDIA/NVTX-Plugins" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref15" class="reference-item">PyTorch, "Profiling with Nsight Systems," PyTorch documentation. <a href="https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html#profiling-with-nsight-systems" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref16" class="reference-item">PyTorch, "torch.cuda.nvtx," PyTorch documentation. <a href="https://pytorch.org/docs/stable/cuda.html#torch.cuda.nvtx.range_push" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref17" class="reference-item">NVIDIA, "Nsight Systems CLI," NVIDIA Developer. <a href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html#cli" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref18" class="reference-item">NVIDIA, "Nsight Systems Command-Line Interface," NVIDIA Developer. <a href="https://docs.nvidia.com/nsight-systems/pdf/Nsight-Systems-CLI.pdf" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref19" class="reference-item">Horovod, "Profiling Horovod with NVIDIA Nsight," Horovod documentation. <a href="https://horovod.readthedocs.io/en/stable/profiling_include.html" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref20" class="reference-item">NVIDIA, "Multi-Node and Multi-Process Support," NVIDIA Developer. <a href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html#multi-node-and-multi-process-support" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref21" class="reference-item">NVIDIA, "Nsight Systems for Multi-GPU and Multi-Node System Profile," NVIDIA On-Demand. <a href="https://www.nvidia.com/en-us/on-demand/session/gtcfall21-a31554/" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref22" class="reference-item">NVIDIA, "Nsight Compute JupyterLab Extension," GitHub. <a href="https://github.com/NVIDIA/Nsight-Compute-Jupyter" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref23" class="reference-item">M. Carper, "Accelerating PyTorch with CUDA Graphs," 2021. <a href="https://pytorch.org/blog/accelerating-pytorch-with-cuda-graphs/" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref24" class="reference-item">NVIDIA, "Nsight Compute Pro-Tips," NVIDIA Developer. <a href="https://developer.nvidia.com/blog/nsight-compute-pro-tips-to-accelerate-your-cuda-kernels/" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref25" class="reference-item">NVIDIA, "Nsight Compute GUI," NVIDIA Developer. <a href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#gui-section" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref26" class="reference-item">NVIDIA, "Guided Analysis," NVIDIA Developer. <a href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#guided-analysis" target="_blank" rel="noopener noreferrer">[Source]</a></li>
                <li id="ref27" class="reference-item">NVIDIA, "Baselines," NVIDIA Developer. <a href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#baselines" target="_blank" rel="noopener noreferrer">[Source]</a></li>
            </ol>
        </footer>
    </div>

    <script>
        // JavaScript for Tab functionality
        function changeTab(event, tabID) {
            // Get all elements with class="tab-content" and hide them
            const tabcontent = document.getElementsByClassName("tab-content");
            for (let i = 0; i < tabcontent.length; i++) {
                tabcontent[i].classList.add("hidden");
            }

            // Get all elements with class="tab-btn" and remove the active class
            const tablinks = document.getElementsByClassName("tab-btn");
            for (let i = 0; i < tablinks.length; i++) {
                tablinks[i].classList.remove("tab-active");
                tablinks[i].classList.add("border-transparent", "text-gray-500", "hover:text-gray-700", "hover:border-gray-300");
            }

            // Show the current tab, and add an "active" class to the button that opened the tab
            document.getElementById(tabID).classList.remove("hidden");
            event.currentTarget.classList.add("tab-active");
            event.currentTarget.classList.remove("border-transparent", "text-gray-500", "hover:text-gray-700", "hover:border-gray-300");
        }
    </script>

</body>
</html>

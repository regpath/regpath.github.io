<!DOCTYPE html>
<html lang="ko" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GPT-5 주요 이슈 분석</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Noto Sans KR', sans-serif;
        }
        /* Active tab style */
        .tab-active {
            border-color: #3b82f6; /* blue-500 */
            color: #3b82f6;
            background-color: #eff6ff; /* blue-50 */
        }
        /* Tab content panel visibility */
        .tab-panel {
            display: none;
        }
        .tab-panel-active {
            display: block;
        }
        /* Styling for citation links */
        .citation-link {
            color: #2563eb; /* blue-600 */
            font-weight: 500;
            cursor: pointer;
            text-decoration: none;
        }
        .citation-link:hover {
            text-decoration: underline;
        }
        /* Reference item styling */
        .reference-item {
            scroll-margin-top: 2rem; /* Add margin when scrolling to it */
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-800">

    <div class="container mx-auto p-4 sm:p-6 lg:p-8 max-w-7xl">
        <!-- Header -->
        <header class="text-center mb-8">
            <h1 class="text-3xl sm:text-4xl font-bold text-gray-900">플랫폼 쇼크: GPT-5 출시, 기술적 현실과 사용자 신뢰의 균열</h1>
        </header>

        <!-- Tab Navigation -->
        <div class="border-b border-gray-200 mb-6">
            <nav id="tab-nav" class="-mb-px flex flex-wrap" aria-label="Tabs">
                <button class="tab-btn tab-active whitespace-nowrap py-3 px-4 border-b-2 font-medium text-sm" data-tab="intro">서론</button>
                <button class="tab-btn whitespace-nowrap py-3 px-4 border-b-2 font-medium text-sm text-gray-500 hover:text-gray-700 hover:border-gray-300" data-tab="section1">홍보 전략</button>
                <button class="tab-btn whitespace-nowrap py-3 px-4 border-b-2 font-medium text-sm text-gray-500 hover:text-gray-700 hover:border-gray-300" data-tab="section2">기술 평가</button>
                <button class="tab-btn whitespace-nowrap py-3 px-4 border-b-2 font-medium text-sm text-gray-500 hover:text-gray-700 hover:border-gray-300" data-tab="section3">사용자 반발</button>
                <button class="tab-btn whitespace-nowrap py-3 px-4 border-b-2 font-medium text-sm text-gray-500 hover:text-gray-700 hover:border-gray-300" data-tab="section4">출시 논란</button>
                <button class="tab-btn whitespace-nowrap py-3 px-4 border-b-2 font-medium text-sm text-gray-500 hover:text-gray-700 hover:border-gray-300" data-tab="section5">시장 파장</button>
                <button class="tab-btn whitespace-nowrap py-3 px-4 border-b-2 font-medium text-sm text-gray-500 hover:text-gray-700 hover:border-gray-300" data-tab="conclusion">결론</button>
            </nav>
        </div>

        <!-- Tab Content -->
        <main id="tab-content" class="bg-white p-6 sm:p-8 rounded-lg shadow-md">
            <!-- Introduction Panel -->
            <div id="panel-intro" class="tab-panel tab-panel-active">
                <h2 class="text-2xl font-bold mb-4">서론: 높은 기대, 혼란스러운 현실</h2>
                <p class="mb-4 leading-relaxed">2025년 8월 7일, OpenAI는 GPT-5를 인공 일반 지능(AGI)을 향한 기념비적 도약으로 내세웠다.<a href="#ref-1" class="citation-link">[1]</a>, <a href="#ref-2" class="citation-link">[2]</a> 하지만 야심 찬 출시는 곧 사용자들의 거센 반발과 기술적 결함에 부딪혔다. 한 분석가는 이를 "플랫폼 쇼크(platform shock)"라 명명했다.<a href="#ref-3" class="citation-link">[3]</a> 이 보고서는 혁신적 약속과 혼란스러운 현실 사이의 간극을 분석한다.</p>
                <p class="mb-4 leading-relaxed">GPT-5는 점진적이지만 분명한 기술적 진보를 이뤘다. 그러나 출시는 기대 관리, 플랫폼 안정성, 소통 전략 면에서 실패였다. 이 과정에서 사용자 신뢰의 취약성, 중앙화된 AI 인프라의 위험, 그리고 제품 가치에 대한 OpenAI의 근본적인 오해가 드러났다.</p>
                <p class="mb-6 leading-relaxed">이 보고서는 OpenAI의 출시 전 홍보 전략을 분석하고, 모델의 실제 기술과 성능을 평가한다. 이어서 사용자 반발의 원인과 주요 논란을 살펴본 뒤, 시장에 미친 영향과 과대광고 논란을 종합적으로 검토한다.</p>
                
                <div class="bg-gray-50 p-4 rounded-lg mt-6">
                    <h3 class="text-xl font-semibold mb-4 text-gray-700">표 1: GPT-5 출시 전 약속 대 출시 후 현실</h3>
                    <div class="overflow-x-auto">
                        <table class="min-w-full bg-white border border-gray-200 rounded-lg">
                            <thead class="bg-gray-100">
                                <tr>
                                    <th class="p-3 text-left text-sm font-semibold text-gray-600">주장/약속 범주</th>
                                    <th class="p-3 text-left text-sm font-semibold text-gray-600">OpenAI의 출시 전 성명/주장</th>
                                    <th class="p-3 text-left text-sm font-semibold text-gray-600">기록된 출시 후 현실</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr class="border-t">
                                    <td class="p-3 align-top"><strong>지능 및 추론 능력</strong></td>
                                    <td class="p-3 align-top">"GPT-4는 대학생, GPT-5는 박사급 전문가와 대화하는 느낌".<a href="#ref-4" class="citation-link">[4]</a>, <a href="#ref-5" class="citation-link">[5]</a> "역사상 가장 스마트한 모델".<a href="#ref-6" class="citation-link">[6]</a></td>
                                    <td class="p-3 align-top">간단한 십진수 뺄셈 오류 발생.<a href="#ref-7" class="citation-link">[7]</a> 'blueberry에 'b'가 몇 개인지' 같은 단순 논리 오류.<a href="#ref-8" class="citation-link">[8]</a></td>
                                </tr>
                                <tr class="border-t bg-gray-50">
                                    <td class="p-3 align-top"><strong>사용자 경험(UX)</strong></td>
                                    <td class="p-3 align-top">"끔찍한 UX였던 모델 선택기를 없앤" 통합 모델로 사용자 경험 개선.<a href="#ref-9" class="citation-link">[9]</a>, <a href="#ref-10" class="citation-link">[10]</a> "더 유용하고 널리 쓰이는 모델".<a href="#ref-9" class="citation-link">[9]</a></td>
                                    <td class="p-3 align-top">선호도가 높았던 GPT-4o의 갑작스러운 제거로 인한 반발.<a href="#ref-10" class="citation-link">[10]</a>, <a href="#ref-11" class="citation-link">[11]</a> '개성 없는 기업형 좀비'<a href="#ref-6" class="citation-link">[6]</a>, '과로한 비서'<a href="#ref-12" class="citation-link">[12]</a> 등의 비판.</td>
                                </tr>
                                <tr class="border-t">
                                    <td class="p-3 align-top"><strong>안전성 및 신뢰성</strong></td>
                                    <td class="p-3 align-top">"환각 현상 대폭 감소".<a href="#ref-13" class="citation-link">[13]</a>, <a href="#ref-14" class="citation-link">[14]</a> "사실 오류 포함 확률 최대 80% 감소".<a href="#ref-15" class="citation-link">[15]</a> "더 신뢰할 수 있는 조수".<a href="#ref-9" class="citation-link">[9]</a></td>
                                    <td class="p-3 align-top">출시 발표회에서 데이터와 시각적 표현이 불일치하는 "차트 대참사" 발생.<a href="#ref-16" class="citation-link">[16]</a>, <a href="#ref-17" class="citation-link">[17]</a> 모델 자체가 자신의 출시 사실을 모르는 등 환각 현상 지속.<a href="#ref-5" class="citation-link">[5]</a></td>
                                </tr>
                                <tr class="border-t bg-gray-50">
                                    <td class="p-3 align-top"><strong>성능 및 효율성</strong></td>
                                    <td class="p-3 align-top">"코딩, 수학, 작문 등에서 최첨단 성능".<a href="#ref-9" class="citation-link">[9]</a>, <a href="#ref-18" class="citation-link">[18]</a> "더 빠르고 효율적".<a href="#ref-4" class="citation-link">[4]</a></td>
                                    <td class="p-3 align-top">특정 벤치마크(SWE-bench)에서는 최고점, 다른 벤치마크(SimpleBench)에서는 경쟁사에 뒤처지는 5위 기록.<a href="#ref-14" class="citation-link">[14]</a>, <a href="#ref-19" class="citation-link">[19]</a> 응답 속도가 느려지고, 유료 사용자의 사용량 제한이 더 빨리 소진된다는 불만.<a href="#ref-6" class="citation-link">[6]</a>, <a href="#ref-20" class="citation-link">[20]</a></td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>

            <!-- Section 1 Panel -->
            <div id="panel-section1" class="tab-panel">
                <h2 class="text-2xl font-bold mb-4">섹션 1: "박사급 전문가"의 약속 - OpenAI의 출시 전 홍보 전략</h2>
                <div class="space-y-6">
                    <div class="p-4 border-l-4 border-blue-300 bg-blue-50 rounded-r-lg">
                        <h3 class="text-xl font-semibold mb-2 text-gray-800">1.1 '올트먼 독트린': 패러다임 전환의 약속</h3>
                        <p class="leading-relaxed">CEO 샘 올트먼은 이례적으로 높은 기대치를 조성했다. 그는 모델의 성능을 맨해튼 프로젝트에 비유하며 "우리가 무슨 짓을 한 거지?"라고 자문할 순간이라고 말했다.<a href="#ref-1" class="citation-link">[1]</a>, <a href="#ref-21" class="citation-link">[21]</a> 이는 단순한 성능 향상을 넘어, GPT-5를 세상을 바꿀 기술로 포장해 기대를 최고조로 끌어올렸다. 그는 지능의 도약을 "대학생"(GPT-4)에서 "박사급 전문가"(GPT-5)로 비유하며 질적 개선을 약속했다.<a href="#ref-2" class="citation-link">[2]</a>, <a href="#ref-4" class="citation-link">[4]</a>, <a href="#ref-5" class="citation-link">[5]</a>, <a href="#ref-13" class="citation-link">[13]</a> 또한 테스트 중 "쓸모없다"고 느끼고 "두려웠다"고 고백하며 모델의 신비감을 증폭시켰다.<a href="#ref-1" class="citation-link">[1]</a>, <a href="#ref-21" class="citation-link">[21]</a>, <a href="#ref-22" class="citation-link">[22]</a></p>
                    </div>
                    <div class="p-4 border-l-4 border-blue-300 bg-blue-50 rounded-r-lg">
                        <h3 class="text-xl font-semibold mb-2 text-gray-800">1.2 공식 발표: 더 스마트하고 안전한 통합 AI</h3>
                        <p class="leading-relaxed">OpenAI의 공식 발표는 이러한 서사를 뒷받침했다. 코딩, 수학, 작문, 헬스케어 등에서 최첨단 성능을 갖춘 "능력과 지능의 중대한 도약"을 약속했다.<a href="#ref-9" class="citation-link">[9]</a>, <a href="#ref-18" class="citation-link">[18]</a>, <a href="#ref-23" class="citation-link">[23]</a> 핵심 약속 중 하나는 환각이나 아첨 같은 고질적 결함을 줄여 GPT-5를 "더 신뢰할 수 있는 조수"로 만드는 것이었다.<a href="#ref-9" class="citation-link">[9]</a>, <a href="#ref-13" class="citation-link">[13]</a>, <a href="#ref-15" class="citation-link">[15]</a> 공식 시스템 카드에서는 사실 오류가 최대 80% 감소했다고 주장했다.<a href="#ref-14" class="citation-link">[14]</a>, <a href="#ref-15" class="citation-link">[15]</a> 또한, "통합 모델" 도입을 "끔찍한 UX였던 모델 선택기"를 제거한 사용자 경험 *개선*으로 포장했다.<a href="#ref-4" class="citation-link">[4]</a>, <a href="#ref-9" class="citation-link">[9]</a>, <a href="#ref-10" class="citation-link">[10]</a></p>
                        <p class="mt-4 leading-relaxed">이러한 과대광고는 치열한 경쟁 속에서 기술 리더십을 과시하고, 인재 유치와 기업 가치를 정당화하려는 의도적인 비즈니스 전략이었다.<a href="#ref-12" class="citation-link">[12]</a>, <a href="#ref-13" class="citation-link">[13]</a>, <a href="#ref-24" class="citation-link">[24]</a> 올트먼의 발언들은 경쟁사들이 이루지 못한 기술적 도약을 암시하며 '인식의 해자'를 구축하려 했다. 그러나 제품 경험이 기대에 미치지 못하면서 이 전략은 역효과를 낳았다.</p>
                    </div>
                </div>
            </div>
            
            <!-- Section 2 Panel -->
            <div id="panel-section2" class="tab-panel">
                <h2 class="text-2xl font-bold mb-4">섹션 2: 기술적 진단 - 아키텍처와 성능 평가</h2>
                <div class="space-y-8">
                    <div class="p-4 bg-gray-50 rounded-lg">
                        <h3 class="text-xl font-semibold mb-2">2.1 '통합 모델'의 구조</h3>
                        <p class="mb-4 leading-relaxed">'GPT-5'라는 이름의 모호함은 이것이 단일 모델이 아닌 시스템이라는 점에서 비롯된다.<a href="#ref-9" class="citation-link">[9]</a>, <a href="#ref-25" class="citation-link">[25]</a>, <a href="#ref-26" class="citation-link">[26]</a></p>
                        <ul class="list-disc list-inside space-y-2 pl-2">
                            <li><strong>소비자용 (ChatGPT):</strong> 빠른 일반 모델(`gpt-5-main`)과 복잡한 문제용 추론 모델(`gpt-5-thinking`)으로 구성된다.<a href="#ref-15" class="citation-link">[15]</a>, <a href="#ref-27" class="citation-link">[27]</a> '실시간 결정 라우터'가 자동으로 모델을 선택하는데, 이는 UX 개선을 목표로 했으나 오히려 불만을 샀다.<a href="#ref-9" class="citation-link">[9]</a>, <a href="#ref-10" class="citation-link">[10]</a></li>
                            <li><strong>개발자용 (API):</strong> 개발자용으로는 `gpt-5`, `gpt-5-mini`, `gpt-5-nano` 세 가지 크기의 모델이 출시됐다.<a href="#ref-26" class="citation-link">[26]</a>, <a href="#ref-28" class="citation-link">[28]</a> API의 `gpt-5` 모델은 ChatGPT의 최고 성능을 내는 '추론 모델'로, 소비자용 일반 모델과 구별된다.<a href="#ref-26" class="citation-link">[26]</a> 이 차이점은 일반 사용자에게는 제대로 전달되지 않았다.</li>
                        </ul>
                    </div>
                    <div class="p-4 bg-gray-50 rounded-lg">
                        <h3 class="text-xl font-semibold mb-2">2.2 엇갈리는 성능 평가</h3>
                        <p class="mb-4 leading-relaxed">OpenAI는 특정 벤치마크에서의 최고 수준(SOTA) 결과를 홍보했다. 소프트웨어 엔지니어링 벤치마크인 SWE-bench에서 74.9%<a href="#ref-14" class="citation-link">[14]</a>, <a href="#ref-15" class="citation-link">[15]</a>, <a href="#ref-29" class="citation-link">[29]</a>, 코드 편집 벤치마크인 Aider polyglot에서 88%의 정확도를 기록했다.<a href="#ref-26" class="citation-link">[26]</a> 박사 수준 과학 문제(GPQA)<a href="#ref-14" class="citation-link">[14]</a>와 특정 화학 벤치마크(ChemIQ)<a href="#ref-30" class="citation-link">[30]</a>에서도 뛰어난 성과를 보였다.</p>
                        <p class="leading-relaxed">반면, SimpleBench에서는 56.7%의 점수로 5위에 그치는 등 일부 벤치마크에서는 부진했다.<a href="#ref-19" class="citation-link">[19]</a>, <a href="#ref-31" class="citation-link">[31]</a> 많은 사용자와 비평가들은 개선 폭이 약속했던 수준에 미치지 못하는 점진적 향상에 불과하다고 지적했다.<a href="#ref-6" class="citation-link">[6]</a>, <a href="#ref-19" class="citation-link">[19]</a>, <a href="#ref-32" class="citation-link">[32]</a> 400K 컨텍스트 창(대부분 Pro 사용자에게 128K 제공)도 구글의 1M 토큰 창에 비해 부족하다는 평가를 받았다.<a href="#ref-19" class="citation-link">[19]</a>, <a href="#ref-33" class="citation-link">[33]</a></p>
                    </div>
                    
                    <div class="bg-blue-50 p-4 rounded-lg mt-6">
                        <h3 class="text-xl font-semibold mb-4 text-gray-700">표 2: 벤치마크 성능 비교: GPT-5 대 이전 모델 및 주요 경쟁사</h3>
                        <div class="overflow-x-auto">
                            <table class="min-w-full bg-white border border-gray-200 rounded-lg">
                                <thead class="bg-gray-100">
                                    <tr>
                                        <th class="p-3 text-left text-sm font-semibold text-gray-600">벤치마크 명칭</th>
                                        <th class="p-3 text-left text-sm font-semibold text-gray-600">태스크 유형</th>
                                        <th class="p-3 text-left text-sm font-semibold text-gray-600">GPT-5 점수</th>
                                        <th class="p-3 text-left text-sm font-semibold text-gray-600">GPT-4o/o3 점수</th>
                                        <th class="p-3 text-left text-sm font-semibold text-gray-600">Claude Opus 4.1 점수</th>
                                        <th class="p-3 text-left text-sm font-semibold text-gray-600">Gemini 2.5 Pro 점수</th>
                                        <th class="p-3 text-left text-sm font-semibold text-gray-600">Grok 4 점수</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr class="border-t">
                                        <td class="p-3"><strong>SWE-bench Verified</strong></td>
                                        <td class="p-3">소프트웨어 엔지니어링</td>
                                        <td class="p-3"><strong>74.9%</strong></td>
                                        <td class="p-3">30.8% (4o) / 69.1% (o3)</td>
                                        <td class="p-3">~74%</td>
                                        <td class="p-3">N/A</td>
                                        <td class="p-3">N/A</td>
                                    </tr>
                                    <tr class="border-t bg-gray-50">
                                        <td class="p-3"><strong>Aider polyglot</strong></td>
                                        <td class="p-3">다국어 코드 편집</td>
                                        <td class="p-3"><strong>88%</strong></td>
                                        <td class="p-3">81% (o3)</td>
                                        <td class="p-3">N/A</td>
                                        <td class="p-3">N/A</td>
                                        <td class="p-3">N/A</td>
                                    </tr>
                                    <tr class="border-t">
                                        <td class="p-3"><strong>GPQA (Diamond)</strong></td>
                                        <td class="p-3">박사 수준 과학 질문</td>
                                        <td class="p-3"><strong>88.4% (Pro)</strong></td>
                                        <td class="p-3">77.2% (o3-Pro)</td>
                                        <td class="p-3">N/A</td>
                                        <td class="p-3">N/A</td>
                                        <td class="p-3">N/A</td>
                                    </tr>
                                    <tr class="border-t bg-gray-50">
                                        <td class="p-3"><strong>SimpleBench</strong></td>
                                        <td class="p-3">일반 상식 추론</td>
                                        <td class="p-3">56.7%</td>
                                        <td class="p-3">N/A</td>
                                        <td class="p-3">N/A</td>
                                        <td class="p-3">N/A</td>
                                        <td class="p-3"><strong>>56.7% (상위)</strong></td>
                                    </tr>
                                     <tr class="border-t">
                                        <td class="p-3"><strong>ChemIQ</strong></td>
                                        <td class="p-3">화학 지능</td>
                                        <td class="p-3"><strong>70.2%</strong></td>
                                        <td class="p-3">N/A</td>
                                        <td class="p-3">N/A</td>
                                        <td class="p-3">&lt;70.2%</td>
                                        <td class="p-3">N/A</td>
                                    </tr>
                                     <tr class="border-t bg-gray-50">
                                        <td class="p-3"><strong>2D NMR Elucidation</strong></td>
                                        <td class="p-3">화학 구조 분석</td>
                                        <td class="p-3">6%</td>
                                        <td class="p-3">6% (o3-mini)</td>
                                        <td class="p-3">N/A</td>
                                        <td class="p-3"><strong>20%</strong></td>
                                        <td class="p-3">N/A</td>
                                    </tr>
                                     <tr class="border-t">
                                        <td class="p-3"><strong>MMLU</strong></td>
                                        <td class="p-3">다중 작업 언어 이해</td>
                                        <td class="p-3">(기존 모델과 유사)</td>
                                        <td class="p-3">(기존 모델과 유사)</td>
                                        <td class="p-3">N/A</td>
                                        <td class="p-3">N/A</td>
                                        <td class="p-3">N/A</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                        <p class="text-xs text-gray-500 mt-2 italic">*참고: 점수는 사용된 모델 버전(예: thinking, pro)에 따라 다를 수 있으며, 일부 경쟁사 점수는 직접 비교가 어려울 수 있음.</p>
                    </div>

                    <div class="p-4 bg-gray-50 rounded-lg">
                        <h3 class="text-xl font-semibold mb-2">2.3 여전한 근본적 결함</h3>
                        <p class="mb-4 leading-relaxed">환각을 줄였다는 주장에도 불구하고, 문제는 여전하다. 사용자들은 모델이 사실을 날조하고, 출처를 지어내며, 자신의 출시일에 대해서도 오류를 보인다고 보고했다.<a href="#ref-5" class="citation-link">[5]</a>, <a href="#ref-8" class="citation-link">[8]</a>, <a href="#ref-31" class="citation-link">[31]</a>, <a href="#ref-32" class="citation-link">[32]</a> 기본적인 추론과 수학 오류도 지속되었다. 출시 데모에서 간단한 십진수 뺄셈 오류가 발생했고 <a href="#ref-7" class="citation-link">[7]</a>, '단계별로 생각하라'고 지시하지 않으면 간단한 논리 문제도 틀렸다.<a href="#ref-8" class="citation-link">[8]</a>, <a href="#ref-19" class="citation-link">[19]</a> 이런 결함들은 '박사급 전문가'나 '신뢰할 수 있는 모델'이라는 주장과 모순된다.</p>
                        <p class="leading-relaxed">이러한 성능 불균형은 OpenAI가 SWE-bench와 같은 특정 벤치마크에 훈련을 집중하고, 일반적인 추론 능력은 소홀히 했을 가능성을 시사한다. 이는 특정 영역에서는 뛰어나지만 상식적인 작업에서는 실패하는 '취약한' 지능을 낳는다. 즉, '박사급 전문가'는 복잡한 계산은 풀지만 단어의 글자 수를 세지 못하는 사반트 증후군(savant syndrome)과 유사하다. 이는 약속된 범용 지능이 아닌, 좁은 인공지능의 특징이다. 이 때문에 코딩 개발자들은 감명받았지만, 창작자나 일반 사용자들은 실망한 것으로 보인다.<a href="#ref-6" class="citation-link">[6]</a>, <a href="#ref-19" class="citation-link">[19]</a>, <a href="#ref-26" class="citation-link">[26]</a>, <a href="#ref-34" class="citation-link">[34]</a></p>
                    </div>
                </div>
            </div>

            <!-- Section 3 Panel -->
            <div id="panel-section3" class="tab-panel">
                 <h2 class="text-2xl font-bold mb-4">섹션 3: 사용자 반발 - "신뢰하는 파트너"에서 "개성 없는 기업형 좀비"로</h2>
                 <div class="space-y-6">
                    <div class="p-4 border-l-4 border-green-300 bg-green-50 rounded-r-lg">
                        <h3 class="text-xl font-semibold mb-2 text-gray-800">3.1 GPT-4o 사태: AI 개성의 힘</h3>
                        <p class="leading-relaxed">가장 큰 논란은 OpenAI가 GPT-4o를 포함한 이전 모델들을 예고 없이 폐기한 결정이었다.<a href="#ref-8" class="citation-link">[8]</a>, <a href="#ref-10" class="citation-link">[10]</a>, <a href="#ref-11" class="citation-link">[11]</a> 이는 개발자들의 작업 흐름을 방해했고,<a href="#ref-3" class="citation-link">[3]</a>, <a href="#ref-19" class="citation-link">[19]</a>, <a href="#ref-35" class="citation-link">[35]</a> GPT-4o의 '개성'에 감정적 유대를 형성했던 사용자들에게는 큰 상실감을 안겨주었다.<a href="#ref-36" class="citation-link">[36]</a>, <a href="#ref-37" class="citation-link">[37]</a>, <a href="#ref-38" class="citation-link">[38]</a> 사용자들은 GPT-4o를 '신뢰하는 친구'나 '영혼'을 가진 파트너로 여겼다.<a href="#ref-11" class="citation-link">[11]</a>, <a href="#ref-36" class="citation-link">[36]</a>, <a href="#ref-39" class="citation-link">[39]</a></p>
                        <p class="mt-4 leading-relaxed">반면 GPT-5는 '개성 없는 기업형 좀비'<a href="#ref-6" class="citation-link">[6]</a>, '영혼 없는'<a href="#ref-39" class="citation-link">[39]</a>, '과로에 시달리는 비서'<a href="#ref-12" class="citation-link">[12]</a>, <a href="#ref-19" class="citation-link">[19]</a> 등으로 묘사되었다. 이는 단순한 스타일 차이를 넘어 관계의 상실로 받아들여졌다.</p>
                    </div>
                    <div class="p-4 border-l-4 border-green-300 bg-green-50 rounded-r-lg">
                        <h3 class="text-xl font-semibold mb-2 text-gray-800">3.2 성능 저하와 '슈링크플레이션' 논란</h3>
                        <p class="leading-relaxed">사용자들은 성능 저하도 지적했다. 짧은 답변, 느린 응답 속도, 지시 불이행 등이 주된 불만이었다.<a href="#ref-6" class="citation-link">[6]</a>, <a href="#ref-11" class="citation-link">[11]</a>, <a href="#ref-20" class="citation-link">[20]</a>, <a href="#ref-40" class="citation-link">[40]</a>, <a href="#ref-41" class="citation-link">[41]</a> 유료 사용자들은 사용량 한도에 더 빨리 도달한다고 보고했다.<a href="#ref-12" class="citation-link">[12]</a>, <a href="#ref-19" class="citation-link">[19]</a>, <a href="#ref-41" class="citation-link">[41]</a> 이는 비용 절감을 위한 '슈링크플레이션'이라는 추측으로 이어졌다.<a href="#ref-12" class="citation-link">[12]</a>, <a href="#ref-31" class="citation-link">[31]</a>, <a href="#ref-41" class="citation-link">[41]</a> 무료 사용자에게 부과된 엄격한 제한 역시 '모두에게 무료'라는 약속을 무색하게 했다.<a href="#ref-5" class="citation-link">[5]</a>, <a href="#ref-41" class="citation-link">[41]</a></p>
                        <p class="mt-4 leading-relaxed">GPT-4o 사태는 OpenAI의 '얼라인먼트(alignment)'에 대한 편협한 이해를 보여준다. 회사는 기술적 얼라인먼트에 집중했지만, 사용자들은 GPT-4o와 사회적, 감정적 얼라인먼트를 형성했다. OpenAI가 모델의 '아첨 성향'을 일방적으로 수정하면서<a href="#ref-13" class="citation-link">[13]</a> 이 유대를 깨뜨렸다. 이는 진정한 얼라인먼트가 AI 통제를 넘어 사용자 관계를 존중하는 문제임을 시사한다. 위기는 개발자의 안전 정책이 아닌, 사용자의 가치와 정렬하는 데 실패했기 때문에 발생했다.</p>
                    </div>
                </div>
            </div>

            <!-- Section 4 Panel -->
            <div id="panel-section4" class="tab-panel">
                <h2 class="text-2xl font-bold mb-4">섹션 4: 문제적 출시의 해부 - 위기 사례 연구</h2>
                <div class="space-y-6">
                    <div class="p-4 border-l-4 border-red-300 bg-red-50 rounded-r-lg">
                        <h3 class="text-xl font-semibold mb-2 text-gray-800">4.1 '차트 대참사': 신뢰도 하락의 기폭제</h3>
                        <p class="mb-2 leading-relaxed">출시 발표회에서 공개된 벤치마크 그래프는 큰 논란을 일으켰다.</p>
                        <ul class="list-disc list-inside space-y-2 pl-2">
                            <li><strong>오류:</strong> SWE-bench 그래프에서 GPT-5의 52.8% 점수 막대가 o3의 69.1% 막대보다 더 크게 그려졌다.<a href="#ref-16" class="citation-link">[16]</a>, <a href="#ref-17" class="citation-link">[17]</a>, <a href="#ref-42" class="citation-link">[42]</a> 심지어 o3의 69.1% 막대는 GPT-4o의 30.8% 막대와 같은 크기였다.<a href="#ref-17" class="citation-link">[17]</a> 누적 막대와 단순 막대를 혼용하고 범례가 불분명한 점도 문제였다.<a href="#ref-16" class="citation-link">[16]</a></li>
                            <li><strong>반응:</strong> 커뮤니티는 이를 '세기의 최악의 차트 범죄'라며 비판했다.<a href="#ref-17" class="citation-link">[17]</a> 이 사건은 OpenAI의 신뢰도에 타격을 주었고, 무능하거나 의도적으로 조작했다는 의심을 샀다.<a href="#ref-16" class="citation-link">[16]</a>, <a href="#ref-42" class="citation-link">[42]</a> GPT-5가 이 오류를 인식하지 못했다는 점도 비판의 대상이 되었다.<a href="#ref-16" class="citation-link">[16]</a></li>
                            <li><strong>OpenAI의 대응:</strong> 샘 올트먼은 '차트 대참사'라고 인정했고,<a href="#ref-17" class="citation-link">[17]</a> 마케팅팀은 '의도치 않은 오류'라고 해명했다.<a href="#ref-43" class="citation-link">[43]</a> 차트는 블로그에서 수정되었지만, 라이브스트림 영상에는 그대로 남아 실패한 출시의 상징이 되었다.<a href="#ref-17" class="citation-link">[17]</a></li>
                        </ul>
                    </div>
                    <div class="p-4 border-l-4 border-red-300 bg-red-50 rounded-r-lg">
                        <h3 class="text-xl font-semibold mb-2 text-gray-800">4.2 GPT-4o 폐지와 복구 타임라인</h3>
                         <ul class="list-disc list-inside space-y-2 pl-2">
                            <li><strong>출시일 (8월 7일):</strong> GPT-5 출시와 함께 GPT-4o를 포함한 모든 이전 모델이 사전 경고 없이 폐기되었다.<a href="#ref-10" class="citation-link">[10]</a>, <a href="#ref-11" class="citation-link">[11]</a>, <a href="#ref-13" class="citation-link">[13]</a></li>
                            <li><strong>즉각적인 반발 (8월 7-8일):</strong> Reddit, X, OpenAI 포럼 등에서 구독 취소와 GPT-4o 복원 요청이 빗발쳤다.<a href="#ref-11" class="citation-link">[11]</a>, <a href="#ref-12" class="citation-link">[12]</a>, <a href="#ref-36" class="citation-link">[36]</a>, <a href="#ref-38" class="citation-link">[38]</a>, <a href="#ref-41" class="citation-link">[41]</a></li>
                            <li><strong>결정 번복 (8월 8일):</strong> 샘 올트먼은 사용자들이 GPT-4o를 얼마나 소중히 여기는지 '과소평가했다'고 인정하며, Plus 사용자를 위해 GPT-4o를 복구하겠다고 발표했다.<a href="#ref-11" class="citation-link">[11]</a>, <a href="#ref-37" class="citation-link">[37]</a>, <a href="#ref-44" class="citation-link">[44]</a>, <a href="#ref-45" class="citation-link">[45]</a></li>
                            <li><strong>해명:</strong> 올트먼은 출시 당일 '자동 전환기' 고장으로 GPT-5가 실제보다 성능이 낮아 보였다고 해명했다.<a href="#ref-11" class="citation-link">[11]</a>, <a href="#ref-44" class="citation-link">[44]</a> 이는 성능 저하에 대한 비판 여론을 관리하려는 시도로 해석된다.</li>
                        </ul>
                        <p class="mt-4 leading-relaxed">이 '자동 전환기 고장' 설명은 모델 자체의 문제나 과대광고를 인정하지 않으면서 성능 불만을 잠재우려는 의도로 보인다. 비난의 화살을 핵심 제품에서 부품으로 돌리고, '진짜' GPT-5는 더 나을 것이라고 암시하는 것이다. 이는 기술적으로 반증하기 어려운 해명으로, '슈링크플레이션'이나 실망스러운 성능이라는 더 근본적인 비판에서 주의를 돌리려는 위기관리 전술로 해석될 수 있다.</p>
                    </div>
                </div>
            </div>

            <!-- Section 5 Panel -->
            <div id="panel-section5" class="tab-panel">
                <h2 class="text-2xl font-bold mb-4">섹션 5: 시장 파장과 미래 전망</h2>
                <div class="space-y-6">
                    <div class="p-4 border-l-4 border-purple-300 bg-purple-50 rounded-r-lg">
                        <h3 class="text-xl font-semibold mb-2 text-gray-800">5.1 경쟁 구도와 흔들리는 입지</h3>
                        <p class="leading-relaxed">이번 출시는 리더로서 OpenAI의 명성을 훼손하고 '취약해진 해자'를 드러냈다.<a href="#ref-24" class="citation-link">[24]</a> 일론 머스크 같은 경쟁자들은 즉시 공세에 나섰다.<a href="#ref-5" class="citation-link">[5]</a>, <a href="#ref-46" class="citation-link">[46]</a> 이 사건은 OpenAI API 기반 개발자들에게 심각한 '플랫폼 리스크'를 부각시켰다.<a href="#ref-3" class="citation-link">[3]</a> 모델의 일방적 폐기는 단일 공급업체 의존의 위험성을 보여주며, 안정적인 대안을 찾게 하는 계기가 될 수 있다. GPT-5가 경쟁 모델 대비 점진적 개선에 그쳤다는 인식은, 한 기업이 독주하던 시대가 끝나가고 있음을 시사한다.<a href="#ref-24" class="citation-link">[24]</a>, <a href="#ref-32" class="citation-link">[32]</a></p>
                    </div>
                    <div class="p-4 border-l-4 border-purple-300 bg-purple-50 rounded-r-lg">
                        <h3 class="text-xl font-semibold mb-2 text-gray-800">5.2 과대광고 논란에 대한 평가</h3>
                        <p class="leading-relaxed">결론적으로 GPT-5는 과대 포장되었다는 비판을 피하기 어렵다. '박사급 전문가'라는 주장은 기본적인 오류들로 인해 설득력을 잃었고,<a href="#ref-7" class="citation-link">[7]</a>, <a href="#ref-8" class="citation-link">[8]</a> '신뢰성' 약속은 잘못된 그래프와 계속되는 환각 현상으로 무색해졌다.<a href="#ref-5" class="citation-link">[5]</a>, <a href="#ref-16" class="citation-link">[16]</a> '개선된 UX'는 모델 강제 통합과 성능 저하에 대한 사용자 반발로 이어졌다.<a href="#ref-6" class="citation-link">[6]</a>, <a href="#ref-11" class="citation-link">[11]</a> 코딩 등 특정 분야에서는 최고 수준의 성능을 보였지만,<a href="#ref-26" class="citation-link">[26]</a>, <a href="#ref-29" class="citation-link">[29]</a> 전반적인 사용자 경험은 거창한 홍보를 뒷받침하지 못했다. 마케팅이 제품의 현실을 앞서간 대표적인 사례다.</p>
                        <p class="mt-4 leading-relaxed">GPT-5 출시는 AI 산업의 전환점이 될 수 있다. 수많은 사용자가 모델을 일상에 통합하면서, AI는 단순한 제품을 넘어 중요한 인프라가 되었다. 이번 '플랫폼 쇼크'는 '빠르게 움직이고 파괴하라'는 식의 접근이 더는 유효하지 않음을 보여준다. 안정성, 예측 가능성, 투명한 소통이 중요해졌다. 수억 명의 사용자가 의존하는 상황에서,<a href="#ref-24" class="citation-link">[24]</a> OpenAI는 하룻밤 사이에 8개 모델을 폐기하는 등 여전히 스타트업처럼 행동했다.<a href="#ref-10" class="citation-link">[10]</a>, <a href="#ref-11" class="citation-link">[11]</a> 반발은 얼리 어답터가 아닌, 서비스 중단을 겪은 성숙한 사용자층에서 나왔다. 이는 OpenAI의 실패가 단순한 홍보 실수가 아니라, 스스로가 연구소에서 글로벌 인프라 제공자로 변모했음을 인지하지 못한 데 있음을 보여준다. 미래의 성공은 혁신만큼이나 신뢰와 안정성에 달려있다.</p>
                    </div>
                </div>
            </div>

            <!-- Conclusion Panel -->
            <div id="panel-conclusion" class="tab-panel">
                 <h2 class="text-2xl font-bold mb-4">결론: 플랫폼 쇼크의 교훈</h2>
                 <p class="mb-4 leading-relaxed">GPT-5는 기술적으로 점진적 발전을 이루었지만, 그 성과는 미숙한 출시 전략에 가려졌다. 과장된 마케팅, 결함 있는 발표, 기존 기능의 일방적 제거, 사용자 경험 저하가 맞물려 부정적 여론을 키웠다.</p>
                 <p class="mb-4 leading-relaxed">핵심 교훈은 기술적 성과에 대한 집착이 사용자 중심 설계와 소통을 압도했다는 점이다. OpenAI는 이번 사태를 통해 플랫폼 규모에 걸맞은 신뢰와 안정성이 모델 성능만큼 중요하다는 것을 깨달았을 것이다.</p>
                 <p class="mb-4 leading-relaxed">이번 '플랫폼 쇼크'는 지속적인 파급 효과를 낳을 것이다. 경쟁자들에게 기회를 주고, 개발자들에게는 플랫폼 리스크를 각인시켰으며, OpenAI를 수세에 몰리게 했다. 투명성, 사용자 선택권, 안정적인 로드맵을 통해 신뢰를 회복하는 것이 GPT-6 개발만큼이나 중요해졌다. AI가 단순한 도구를 넘어 복잡한 사회-기술 인프라로 자리 잡은 지금, 개발자들에게는 더 높은 수준의 성숙함이 요구된다.</p>
            </div>
        </main>

        <!-- References Section -->
        <footer id="references" class="mt-12 pt-8 border-t-2 border-gray-300">
            <h2 class="text-2xl font-bold mb-6 text-center">참고문헌</h2>
            <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4 text-sm">
                <!-- Dynamically inserted reference items will go here -->
            </div>
        </footer>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const tabs = document.querySelectorAll('.tab-btn');
            const panels = document.querySelectorAll('.tab-panel');
            const tabNav = document.getElementById('tab-nav');

            // --- Tab Switching Logic ---
            tabNav.addEventListener('click', (e) => {
                if (e.target.classList.contains('tab-btn')) {
                    const tabName = e.target.dataset.tab;

                    // Deactivate all tabs and panels
                    tabs.forEach(tab => {
                        tab.classList.remove('tab-active');
                        tab.classList.add('text-gray-500', 'hover:text-gray-700', 'hover:border-gray-300');
                    });
                    panels.forEach(panel => {
                        panel.classList.remove('tab-panel-active');
                    });

                    // Activate clicked tab and corresponding panel
                    e.target.classList.add('tab-active');
                    e.target.classList.remove('text-gray-500', 'hover:text-gray-700', 'hover:border-gray-300');
                    document.getElementById(`panel-${tabName}`).classList.add('tab-panel-active');
                }
            });

            // --- Reference Generation and Linking Logic ---
            const references = [
                { id: 1, site: 'AP News', title: 'OpenAI launches GPT-5, a potential barometer for whether AI hype is justified.', url: 'https://apnews.com/article/gpt5-openai-chatgpt-artificial-intelligence-d12cd2d6310a2515042067b5d3965aa1' },
                { id: 2, site: 'KBS 뉴스', title: '오픈AI, GPT-5 공개…“박사급 전문가와 대화하는 느낌”.', url: 'https://news.kbs.co.kr/news/view.do?ncd=8324903' },
                { id: 3, site: 'Reddit', title: '[Essay] An Analysis of the GPT-5 Platform Shock.', url: 'https://www.reddit.com/r/singularity/comments/1mm5kzf/essay_an_analysis_of_the_gpt5_platform_shock/' },
                { id: 4, site: 'KBS 뉴스', title: '오픈AI, GPT-5 공개…“박사급 전문가와 대화하는 느낌”.', url: 'https://news.kbs.co.kr/news/view.do?ncd=8324903' },
                { id: 5, site: '다음뉴스', title: '[단독] 가장 똑똑하다던 GPT-5, 본인 출시도 몰라 할루시네이션 논란.', url: 'https://v.daum.net/v/20250808110715253' },
                { id: 6, site: 'Windows Central', title: 'Did Sam Altman oversell GPT-5? OpenAI faces backlash for ruining ChatGPT, turning it into a \'corporate beige zombie\'.', url: 'https://www.windowscentral.com/artificial-intelligence/openai-chatgpt/did-sam-altman-oversell-gpt-5-openai-faces-backlash-for-ruining-chatgpt-turning-it-into-a-corporate-beige-zombie' },
                { id: 7, site: 'Times of India', title: 'Sam Altman says ChatGPT-5 is an expert, a small maths slip shows why it\'s still not perfect.', url: 'https://timesofindia.indiatimes.com/technology/tech-news/sam-altman-says-chatgpt-5-is-an-expert-a-small-maths-slip-shows-why-its-still-not-perfect/articleshow/123188241.cms' },
                { id: 8, site: 'Cryptopolitan', title: 'OpenAI’s GPT-5 draws mixed reviews on day one.', url: 'https://www.cryptopolitan.com/ko/openai-gpt-5-draws-mixed-reviews-on-day-one/' },
                { id: 9, site: 'Simon Willison\'s Blog', title: 'The surprise deprecation of GPT-4o for ChatGPT consumers.', url: 'https://simonwillison.net/2025/Aug/8/surprise-deprecation-of-gpt-4o/' },
                { id: 10, site: 'PCMag', title: 'OpenAI Faces Backlash for Retiring Older Models With GPT-5 Launch.', url: 'https://www.pcmag.com/news/openai-faces-backlash-for-retiring-older-models-with-gpt-5-launch' },
                { id: 11, site: 'PCMag', title: 'OpenAI Faces Backlash for Retiring Older Models With GPT-5 Launch.', url: 'https://www.pcmag.com/news/openai-faces-backlash-for-retiring-older-models-with-gpt-5-launch' },
                { id: 12, site: 'Futurism', title: 'GPT-5 Users Say It Seriously Sucks.', url: 'https://futurism.com/gpt-5-sucks' },
                { id: 13, site: 'ZDNet Korea', title: '\'생각하는 AI\' GPT-5 나왔다…\'모든 영역 박사급 수준\'.', url: 'https://zdnet.co.kr/view/?no=20250808084540' },
                { id: 14, site: 'OpenAI', title: 'GPT-5 System Card.', url: 'https://cdn.openai.com/pdf/8124a3ce-ab78-4f06-96eb-49ea29ffb52f/gpt5-system-card-aug7.pdf' },
                { id: 15, site: 'OpenAI', title: 'GPT-5 System Card.', url: 'https://cdn.openai.com/pdf/8124a3ce-ab78-4f06-96eb-49ea29ffb52f/gpt5-system-card-aug7.pdf' },
                { id: 16, site: 'Futurism', title: 'GPT-5 Launch Demo Plagued With Catastrophically Dumb Errors.', url: 'https://futurism.com/gpt-5-demo-dumb-errors' },
                { id: 17, site: '디지털투데이', title: '샘 알트먼, GPT-5 성능 논란에 "GPT-4o 다시 제공할 것".', url: 'https://www.digitaltoday.co.kr/news/articleView.html?idxno=583793' },
                { id: 18, site: 'The Economic Times', title: 'OpenAI introduces ChatGPT 5: Features, performance, access, pricing, here\'s all you need to know.', url: 'https://economictimes.indiatimes.com/magazines/panache/openai-introduces-chatgpt-5-features-performance-access-pricing-heres-all-you-need-to-know/articleshow/123174283.cms' },
                { id: 19, site: 'Medium', title: 'GPT-5: OpenAI’s Worst Release Yet?', url: 'https://medium.com/data-science-in-your-pocket/gpt-5-openais-worst-release-yet-421558ad89f4' },
                { id: 20, site: 'Reddit', title: 'GPT5 is horrible.', url: 'https://www.reddit.com/r/ChatGPT/comments/1mkd4l3/gpt5_is_horrible/' },
                { id: 21, site: 'Times of India', title: '\'What have we done?\': Sam Altman says \'I feel useless\', compares ChatGPT-5\'s power to the Manhattan Project.', url: 'https://timesofindia.indiatimes.com/technology/tech-news/what-have-we-done-sam-altman-says-i-feel-useless-compares-chatgpt-5s-power-to-the-manhattan-project/articleshow/123112813.cms' },
                { id: 22, site: 'The Economic Times', title: 'GPT-5 launch: \'People have tried for 50 yrs\', Satya Nadella replies to Elon Musk\'s threat that OpenAI will \'eat Microsoft alive\'.', url: 'https://economictimes.indiatimes.com/news/new-updates/gpt-5-launch-people-have-tried-for-50-yrs-satya-nadella-replies-to-elon-musks-threat-that-openai-will-eat-microsoft-alive/articleshow/123184483.cms' },
                { id: 23, site: 'YouTube (OpenAI)', title: 'Introducing GPT-5.', url: 'https://www.youtube.com/watch?v=boJG84Jcf-4' },
                { id: 24, site: 'AP News', title: 'OpenAI launches GPT-5, a potential barometer for whether AI hype is justified.', url: 'https://apnews.com/article/gpt5-openai-chatgpt-artificial-intelligence-d12cd2d6310a2515042067b5d3965aa1' },
                { id: 25, site: 'KBS 뉴스', title: '오픈AI, GPT-5 공개…“박사급 전문가와 대화하는 느낌”.', url: 'https://news.kbs.co.kr/news/view.do?ncd=8324903' },
                { id: 26, site: 'OpenAI', title: 'Introducing GPT‑5 for developers.', url: 'https://openai.com/index/introducing-gpt-5-for-developers/' },
                { id: 27, site: 'The Neuron', title: 'GPT-5 is here. Here\'s everything you need to know so far.', url: 'https://www.theneuron.ai/explainer-articles/gpt-5-is-here-heres-everything-you-need-to-know-so-far' },
                { id: 28, site: 'Times of India', title: 'OpenAI CEO Sam Altman at GPT-5 launch: India is our second-largest market...but what users are doing with...', url: 'https://timesofindia.indiatimes.com/technology/tech-news/openai-ceo-sam-altman-at-gpt-5-launch-india-is-our-second-largest-marketbut-what-users-are-doing-with/articleshow/123178437.cms' },
                { id: 29, site: '중앙일보 (Korea Daily)', title: '“코딩, 박사급으로 잘하네”...오픈AI, GPT-5 공개.', url: 'https://www.koreadaily.com/article/20250808001303169' },
                { id: 30, site: 'Blopig', title: 'GPT-5 achieves state-of-the-art chemical intelligence.', url: 'https://www.blopig.com/blog/2025/08/gpt-5-achieves-state-of-the-art-chemical-intelligence/' },
                { id: 31, site: 'Reddit', title: 'GPT-5 scores a poor 56.7% on SimpleBench, putting it at 5th place.', url: 'https://www.reddit.com/r/singularity/comments/1mkgi1a/gpt5_scores_a_poor_567_on_simplebench_putting_it/' },
                { id: 32, site: 'Marginal Revolution', title: 'GPT-5 short and enthusiastic review.', url: 'https://marginalrevolution.com/marginalrevolution/2025/08/gpt-5-short-and-enthusiastic-review.html' },
                { id: 33, site: 'Reddit', title: 'GPT-5 Is Underwhelming.', url: 'https://www.reddit.com/r/OpenAI/comments/1mk8hqd/gpt5_is_underwhelming/' },
                { id: 34, site: 'Reddit', title: 'Want feedback on GPT5? Here it is.', url: 'https://www.reddit.com/r/ChatGPT/comments/1mlmfnu/want_feedback_on_gpt5_here_it_is/' },
                { id: 35, site: 'OpenAI Community', title: 'OpenAI is taking GPT-4o away from me despite promising they wouldn\'t.', url: 'https://community.openai.com/t/openai-is-taking-gpt-4o-away-from-me-despite-promising-they-wouldnt/1337378' },
                { id: 36, site: 'OpenAI Community', title: 'Please fight to get back access to GPT-4o!', url: 'https://community.openai.com/t/please-fight-to-get-back-access-to-gpt-4o/1338111' },
                { id: 37, site: 'Tom\'s Guide', title: 'ChatGPT-4o is coming back after massive GPT-5 backlash — here\'s what happened.', url: 'https://www.tomsguide.com/ai/chatgpt-4o-is-coming-back-after-massive-gpt-5-backlash-heres-what-happened' },
                { id: 38, site: 'Reddit', title: 'If you miss 4o, speak up now. Contact OpenAI support.', url: 'https://www.reddit.com/r/ChatGPT/comments/1mkzj15/if_you_miss_4o_speak_up_now_contact_openai_support/' },
                { id: 39, site: 'Simon Willison\'s Blog', title: 'The surprise deprecation of GPT-4o for ChatGPT consumers.', url: 'https://simonwillison.net/2025/Aug/8/surprise-deprecation-of-gpt-4o/' },
                { id: 40, site: 'Reddit', title: 'GPT5 is horrible.', url: 'https://www.reddit.com/r/ChatGPT/comments/1mkd4l3/gpt5_is_horrible/' },
                { id: 41, site: 'Futurism', title: 'GPT-5 Users Say It Seriously Sucks.', url: 'https://futurism.com/gpt-5-sucks' },
                { id: 42, site: 'Hacker News', title: 'What\'s going on with their SWE bench graph?', url: 'https://news.ycombinator.com/item?id=44827179' },
                { id: 43, site: '디지털투데이', title: '샘 알트먼, GPT-5 성능 논란에 "GPT-4o 다시 제공할 것".', url: 'https://www.digitaltoday.co.kr/news/articleView.html?idxno=583793' },
                { id: 44, site: 'MacRumors', title: 'ChatGPT Plus Users Can Keep Using GPT-4o After Complaints About GPT-5.', url: 'https://www.macrumors.com/2025/08/08/openai-gpt-5-complaints/' },
                { id: 45, site: 'TechRadar', title: 'So many ChatGPT users have said they\'re missing the older GPT-4o model, OpenAI is going to bring it back.', url: 'https://www.techradar.com/ai-platforms-assistants/chatgpt/so-many-chatgpt-users-have-said-theyre-missing-the-older-gpt-4o-model-openai-is-going-to-bring-it-back' },
                { id: 46, site: 'Times of India', title: 'Elon Musk says OpenAI will \'eat Microsoft alive\' as Nadella champions GPT-5 rollout.', url: 'https://timesofindia.indiatimes.com/technology/tech-news/elon-musk-says-openai-will-eat-microsoft-alive-as-nadella-champions-gpt-5-rollout/articleshow/123183029.cms' }
            ];

            const referencesContainer = document.querySelector('#references .grid');
            references.forEach(ref => {
                const refElement = document.createElement('div');
                refElement.id = `ref-${ref.id}`;
                refElement.className = 'reference-item p-4 bg-gray-100 rounded-lg';
                refElement.innerHTML = `
                    <p class="font-semibold text-gray-500">${ref.id}. ${ref.site}</p>
                    <a href="${ref.url}" target="_blank" rel="noopener noreferrer" class="text-blue-600 hover:underline">
                        ${ref.title}
                    </a>
                `;
                referencesContainer.appendChild(refElement);
            });
        });
    </script>

</body>
</html>

<!DOCTYPE html>
<html lang="ko">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>PIM 구조</title>
<style>
body {
font-family: 'Malgun Gothic', '맑은 고딕', sans-serif;
line-height: 1.6;
color: #333;
max-width: 800px;
margin: 20px auto;
padding: 0 20px;
background-color: #f9f9f9;
}
h1, h2, h3 {
color: #2c3e50;
border-bottom: 2px solid #3498db;
padding-bottom: 10px;
margin-top: 40px;
}
h1 {
font-size: 2.5em;
text-align: center;
}
h2 {
font-size: 2em;
}
h3 {
font-size: 1.5em;
border-bottom: 1px solid #ccc;
}
p {
text-align: justify;
margin-bottom: 15px;
}
ul, ol {
padding-left: 20px;
}
li {
margin-bottom: 10px;
}
table {
width: 100%;
border-collapse: collapse;
margin: 25px 0;
font-size: 0.9em;
box-shadow: 0 0 20px rgba(0, 0, 0, 0.15);
}
thead tr {
background-color: #3498db;
color: #ffffff;
text-align: left;
}
th, td {
padding: 12px 15px;
border: 1px solid #ddd;
}
tbody tr {
border-bottom: 1px solid #dddddd;
}
tbody tr:nth-of-type(even) {
background-color: #f3f3f3;
}
tbody tr:last-of-type {
border-bottom: 2px solid #3498db;
}
strong {
color: #2980b9;
}
code {
background-color: #ecf0f1;
padding: 2px 5px;
border-radius: 3px;
font-family: 'Courier New', Courier, monospace;
}
</style>
</head>
<body>
<h1>SK 하이닉스 GDDR6-AiM에 대한 심층 기술 분석: 아키텍처, 소프트웨어, 성능 및 메모리 중심 컴퓨팅 시대의 미래</h1>
<h2>서론: 메모리 중심 컴퓨팅으로의 패러다임 전환</h2>
<h3>폰 노이만 병목 현상과 메모리 장벽의 심화</h3>
<p>지난 수십 년간 컴퓨팅 시스템의 근간을 이루어 온 폰 노이만(von Neumann) 아키텍처는 프로세서(CPU/GPU)와 메모리(DRAM)를 물리적으로 분리하는 구조를 특징으로 한다. 이러한 구조는 유연성과 범용성을 제공하며 컴퓨팅 기술의 발전을 이끌었지만, 데이터 중심의 현대적 워크로드 앞에서 근본적인 한계에 직면했다. 프로세서가 데이터를 처리하기 위해서는 반드시 메모리로부터 데이터를 가져와야 하는데, 이 과정에서 발생하는 지연과 에너지 소모가 시스템 전체 성능의 발목을 잡는 '폰 노이만 병목 현상'이 바로 그것이다.</p>
<p>이 문제는 '메모리 장벽(Memory Wall)'이라는 현상으로 더욱 심화되었다. 프로세서의 연산 속도는 무어의 법칙에 따라 기하급수적으로 증가해 온 반면, 메모리 접근 속도(대역폭 및 지연 시간)의 개선은 이를 따라가지 못했다. 그 결과, 최신 프로세서는 대부분의 시간을 실제 연산이 아닌, 데이터를 기다리거나 이동시키는 데 허비하게 되었다. 특히 인공지능(AI), 빅데이터, 고성능 컴퓨팅(HPC)과 같이 방대한 양의 데이터를 처리해야 하는 워크로드에서 이 문제는 극명하게 드러난다. 일례로, DRAM에서 데이터를 가져와 부동소수점 연산 한 번을 수행하는 데 드는 에너지는 실제 연산 자체에 드는 에너지보다 수백 배 더 클 수 있다.</p>
<p>이러한 병목 현상을 완화하기 위해 다계층 캐시(multi-level cache)와 같은 전통적인 해결책이 도입되었다. 캐시는 자주 사용하는 데이터를 프로세서 가까이에 위치시켜 메모리 접근을 줄이는 효과적인 방법이다. 그러나 그래프 처리나 대규모 언어 모델(LLM) 추론과 같이 데이터 재사용성이 낮고(low data locality) 데이터셋의 크기가 캐시 용량을 훨씬 초과하는 워크로드에서는 캐시의 효율이 급격히 떨어진다. 결국 시스템은 대부분의 시간을 캐시와 주 메모리 간의 비효율적인 데이터 이동에 소모하게 되며, 이는 PIM(Processing-in-Memory)과 같은 새로운 컴퓨팅 패러다임의 등장을 촉발하는 계기가 되었다. 이는 기존 캐시 계층 구조의 개선만으로는 더 이상 데이터 중심 시대의 요구를 충족시키기 어렵다는 아키텍처적 한계에 대한 인정이기도 하다.</p>
<h3>PIM (Processing-in-Memory) 기술의 대두</h3>
<p>PIM은 데이터 이동을 최소화하기 위해 연산 기능을 데이터가 저장된 위치, 즉 메모리 내부에 통합하거나 매우 가깝게 배치하는 컴퓨팅 패러다임이다. '데이터를 연산 장치로 가져오는' 전통적인 방식에서 벗어나 '연산 기능을 데이터가 있는 곳으로 옮기는' 혁신적인 접근법을 통해, 폰 노이만 병목 현상의 근본적인 해결을 목표로 한다. PIM 기술은 크게 두 가지 방식으로 분류할 수 있다.</p>
<p>첫째는 <strong>Processing-Using-Memory (PuM)</strong>로, 메모리 셀의 물리적, 아날로그적 특성을 활용하여 별도의 로직 유닛 없이 연산을 수행하는 방식이다. 이는 기존 메모리 아키텍처에 최소한의 변경만을 가하지만, 수행 가능한 연산의 종류가 제한적이다.</p>
<p>둘째는 <strong>Processing-Near-Memory (PnM)</strong>로, 3D 스택 메모리의 로직 다이나 DIMM(Dual In-line Memory Module) 상에 전용 연산 유닛이나 프로세서 코어를 배치하는 방식이다. PuM에 비해 더 복잡하고 다양한 연산을 수행할 수 있으며, 현재 상용화된 대부분의 PIM 제품이 이 방식을 채택하고 있다.</p>
<p>PIM이라는 개념 자체는 수십 년 전부터 존재했지만, 과거에는 메모리와 로직 공정의 통합 어려움, 그리고 PIM의 필요성을 절감할 만한 '킬러 애플리케이션'의 부재 등으로 인해 널리 채택되지 못했다. 그러나 최근 3D 스태킹과 같은 첨단 패키징 기술의 발전과 더불어, AI 시대의 도래는 PIM 기술이 상업적으로 실현될 수 있는 결정적인 환경을 조성했다. 특히, 대규모 언어 모델(LLM)의 등장은 PIM 기술의 상용화를 가속하는 기폭제가 되었다. LLM 추론의 핵심 단계인 자기회귀(autoregressive) 방식의 토큰 생성 과정은 본질적으로 메모리 대역폭에 크게 의존하는 행렬-벡터 곱셈(GEMV) 연산의 연속이기 때문이다. 이러한 워크로드 특성은 연산 집약적인 작업에는 약하지만 메모리 집약적인 작업에 강점을 보이는 PIM 아키텍처의 이상적인 활용 사례가 되었고, 이는 단순한 기술적 호기심을 넘어 시장의 필수적인 요구로 이어졌다.</p>
<h3>SK 하이닉스의 GDDR6-AiM 소개</h3>
<p>이러한 기술적, 시장적 배경 속에서 등장한 SK 하이닉스의 <strong>Accelerator-in-Memory (AiM)</strong>는 상용화된 도메인 특화 PnM 아키텍처의 대표적인 사례다. AiM은 고대역폭 그래픽스 메모리인 GDDR6를 기반으로 설계되었으며, 특히 LLM의 기반이 되는 행렬-벡터 곱셈 연산을 가속화하여 메모리 집약적인 머신러닝 애플리케이션의 성능을 혁신하는 것을 목표로 한다.</p>
<p>본 보고서는 SK 하이닉스의 GDDR6-AiM 기술에 대한 포괄적이고 심층적인 분석을 제공한다. 하드웨어 아키텍처의 세부 사항부터 소프트웨어 스택, 프로그래밍 모델, 성능 벤치마크, 그리고 경쟁 기술과의 비교 분석을 통해 GDDR6-AiM의 기술적 의의와 가치를 평가할 것이다. 나아가, PIM 기술이 직면한 근본적인 한계와 확장성 문제, 그리고 이를 해결하기 위한 CXL(Compute Express Link)과 같은 차세대 인터페이스의 역할을 조명함으로써 메모리 중심 컴퓨팅 시대의 미래를 전망하고자 한다. 결론적으로, GDDR6-AiM은 특정적이지만 매우 중요한 워크로드에 대해 상당한 성능 및 효율성 향상을 제공하며 메모리 중심 컴퓨팅으로 나아가는 중요한 이정표임을 논증할 것이다. 그러나 그 광범위한 채택은 확장성, 프로그래밍 용이성, 시스템 통합이라는 근본적인 과제에 직면해 있으며, 이러한 과제들은 이제 CXL과 같은 새로운 기술을 통해 해결의 실마리를 찾고 있다.</p>
<h2>GDDR6-AiM 하드웨어 아키텍처: 세부 구조 분석</h2>
<p>SK 하이닉스의 GDDR6-AiM은 기존 메모리 기술에 연산 기능을 통합하여 특정 워크로드의 성능을 극대화하는 PnM 아키텍처의 정수를 보여준다. 그 설계 철학은 '병렬성의 극대화'에 있으며, 모든 아키텍처 구성 요소는 이 목표를 달성하기 위해 정교하게 조율되어 있다.</p>
<h3>기반 기술: GDDR6 메모리</h3>
<p>GDDR6-AiM의 근간은 고성능 그래픽스 처리를 위해 개발된 GDDR6 메모리 기술이다. SK 하이닉스의 1y 나노미터 공정 기술로 제작되며, 칩당 8Gb의 메모리 밀도를 가진다. 이 8Gb 칩은 4Gb 다이 두 개를 하나의 패키지에 통합한 DDP(Dual Die Package) 형태로 구성된다. 중요한 점은 1.25V의 낮은 전압에서 동작하여 기존 GDDR6 제품 대비 전력 효율성을 높였다는 것이다.</p>
<p>각 핀당 16 Gb/s의 높은 I/O 데이터 전송률을 통해 칩당 총 64 GB/s의 외부 대역폭을 제공한다. 그러나 AiM 아키텍처의 진정한 가치는 이 외부 대역폭이 아닌, 칩 내부에서 활용 가능한 훨씬 더 높은 내부 대역폭에 있다. AiM은 이 잠재된 내부 대역폭을 연산에 직접 활용함으로써 기존 시스템의 한계를 돌파한다.</p>
<h3>인메모리 연산 엔진: 처리 장치 (Processing Units, PU)</h3>
<p>GDDR6-AiM 아키텍처의 핵심은 칩 내부에 통합된 연산 엔진, 즉 <strong>처리 장치(Processing Unit, PU)</strong>다. 각 다이(die)에는 16개의 PU가 탑재되며, 이는 16개의 DRAM 뱅크(bank) 각각에 하나씩 근접하게 배치되는 전형적인 PnM 구조다. 공개된 다이 사진을 통해 이러한 물리적 배치를 확인할 수 있다.</p>
<p>이 PU들은 1 GHz의 속도로 동작하며, 주로 <strong>곱셈-누산(Multiply-and-Accumulate, MAC)</strong> 연산을 수행하도록 특화되어 있다. 칩은 두 개의 다이로 구성되므로, 칩당 총 32개의 PU가 존재하며, 이를 통해 칩당 1 TFLOPS의 연산 처리량을 달성한다. (다이당 512 GFLOPS). 연산 정밀도는 딥러닝 애플리케이션에 널리 사용되는 <strong>BF16(Brain Floating Point 16)</strong> 형식을 지원하여, 효율성과 정확도 사이의 균형을 맞추었다.</p>
<p>이 아키텍처는 범용성을 희생하는 대신 특정 알고리즘, 즉 LLM의 핵심인 GEMV 연산에 대한 극단적인 최적화를 추구한다. DRAM 공정상에 로직을 구현하는 데 따르는 물리적 제약(느린 속도, 낮은 집적도)을 고려할 때, 이는 필연적인 선택이다. PU를 완전한 코어가 아닌 특화된 MAC 엔진으로 설계하고, 복잡한 활성화 함수를 LUT 기반 근사치 계산으로 대체한 것은 이러한 제약 하에서 효율을 극대화하기 위한 영리한 트레이드오프다.</p>
<h3>핵심 연산 및 데이터 흐름</h3>
<p>GDDR6-AiM의 데이터 흐름은 행렬-벡터 곱셈(y = Wx) 연산에 완벽하게 최적화되어 있다.</p>
<ul>
<li><strong>행렬-벡터 곱셈 (GEMV):</strong> 각 PU는 한 번의 연산 사이클에 16개의 BF16 형식 원소(DRAM의 단일 컬럼 접근에 해당하는 32B)에 대한 MAC 연산을 수행한다.</li>
<li><strong>데이터 소싱 (Data Sourcing):</strong> 연산에 필요한 데이터는 그 특성에 따라 각기 다른 위치에서 공급된다. 거대하고 정적인 <strong>가중치 행렬(W)</strong>은 16개의 DRAM 뱅크에 분산 저장되어 각 PU가 자신의 로컬 뱅크에서 직접, 그리고 빠르게 데이터를 읽어온다. 반면, 작고 자주 변경되는 <strong>입력 벡터(V)</strong>는 모든 PU가 공유하는 <strong>2KB 크기의 전역 버퍼(Global Buffer)</strong>에 먼저 로드된 후, 모든 PU에 동시에 브로드캐스트된다. 이 데이터 배치 및 공급 방식은 데이터 이동을 최소화하고 병렬성을 극대화하는 핵심 설계 원리다.</li>
<li><strong>결과 저장:</strong> 연산 결과는 PU 내부에 위치한 전용 래치(latch)에 저장된다. 중간 MAC 결과는 <strong><code>MAC_REG</code></strong>라는 레지스터 집합에 누적되며, 이를 통해 더 큰 행렬에 대한 연산도 가능하다.</li>
<li><strong>활성화 함수 (Activation Functions):</strong> AiM은 Sigmoid, tanh, GELU와 같은 비선형 활성화 함수를 지원한다. 하지만 이를 위해 복잡한 연산 로직을 추가하는 대신, 사전 계산된 함수 값을 <strong>조회 테이블(Look-Up Table, LUT)</strong> 형태로 DRAM 특정 행에 저장해두고, 선형 보간법(linear interpolation)을 통해 근사치를 계산하는 효율적인 방식을 사용한다. 이 결과는 <strong><code>AF_REG</code></strong>라는 별도의 래치에 저장된다.</li>
</ul>
<h3>병렬성 잠금 해제: "진정한 전체 뱅크" 설계</h3>
<p>SK 하이닉스는 AiM의 설계 목표를 "병렬성과의 타협 없음(No Compromise in Parallelism)"으로 설정하고, 성능이 곧 대역폭과 등가가 되는 시스템을 지향했다. 이를 실현하는 핵심 기술이 바로 <strong>전체 뱅크 동시 연산(all-bank operation)</strong>이다.</p>
<p>기존 DRAM 시스템에서는 외부에서 한 번에 하나의 뱅크에만 접근할 수 있어 칩의 막대한 내부 대역폭을 온전히 활용하기 어려웠다. 그러나 AiM은 모든 PU가 각자의 뱅크에서 동시에 데이터를 읽고 MAC 및 활성화 함수 연산을 병렬로 수행할 수 있도록 설계되었다. 이를 통해 다이당 <strong>512 GB/s</strong>에 달하는 내부 대역폭을 완전히 활용할 수 있게 된다. 이는 외부 대역폭인 32 GB/s(다이당)의 16배에 달하는 수치로, PIM 기술의 핵심적인 가치 제안이 바로 이 내부와 외부 대역폭의 격차를 활용하는 데 있음을 명확히 보여준다. "전체 뱅크 동시 연산"은 잠재적인 병목이었던 메모리 접근을 가속의 원천으로 전환시키는 핵심 메커니즘이다.</p>
<h2>AiM 소프트웨어 스택 및 프로그래밍 모델</h2>
<p>GDDR6-AiM의 혁신적인 하드웨어 아키텍처를 효과적으로 활용하기 위해서는 그에 상응하는 정교한 소프트웨어 스택과 프로그래밍 모델이 필수적이다. AiM 시스템은 단순한 '지능형 메모리'가 아니라, 호스트 프로세서와 긴밀하게 협력하는 명시적인 '가속기' 또는 '코프로세서' 모델로 동작한다. 이는 개발자나 컴파일러가 PIM의 존재를 인지하고, 연산 오프로딩, 데이터 배치, 동기화 등을 명시적으로 관리해야 함을 의미한다.</p>
<h3>시스템 레벨 아키텍처 및 제어 흐름</h3>
<p>AiM 기반 시스템은 연산을 총괄하는 <strong>호스트(CPU 또는 GPU)</strong>와 실제 연산을 수행하는 <strong>AiM 서브시스템</strong>으로 구성된다. 이 둘 사이의 상호작용은 <strong>AiM 컨트롤러</strong>를 통해 이루어진다. SK 하이닉스가 제공하는 레퍼런스 플랫폼에서는 이 컨트롤러가 주로 FPGA(Field-Programmable Gate Array) 상에 구현된다.</p>
<p>AiM 컨트롤러는 호스트로부터 받은 상위 레벨의 요청을 AiM DRAM이 이해할 수 있는 구체적인 명령어 시퀀스로 변환하는 역할을 담당한다. 특히, 컨트롤러는 <strong>AiM 명령어/데이터 DMA(Direct Memory Access)</strong> 엔진을 내장하고 있어, 호스트의 개입을 최소화하면서 명령어와 데이터를 AiM 메모리로 효율적으로 전송할 수 있다. CPU가 모든 PIM 연산을 일일이 관리하는 대신, DMA를 통해 전체 연산 시퀀스를 오프로드하고 다른 작업을 수행할 수 있도록 하는 이 설계는 시스템 전체의 성능 오버헤드를 줄이는 데 결정적인 역할을 한다.</p>
<h3>AiM 명령어 세트: 이중 계층 접근 방식</h3>
<p>AiM의 명령어 체계는 하드웨어의 물리적 동작을 제어하는 저수준 명령어와 호스트와의 통신을 추상화하는 고수준 명령어로 구성된 이중 계층 구조를 가진다.</p>
<ul>
<li><strong>계층 1: 확장된 DRAM 명령어:</strong> 가장 낮은 레벨에서 AiM은 표준 GDDR6 명령어 세트를 PIM 연산을 위해 확장한다. 여기에는 다음과 같은 특수 명령어들이 포함된다.
<ul>
<li><strong>병렬 활성화:</strong> <code>ACT4</code>, <code>ACT16</code> 등 여러 뱅크를 동시에 활성화(activate)하는 명령어.</li>
<li><strong>연산 명령어:</strong> <code>MACSB</code>(단일 뱅크), <code>MAC4B</code>(4개 뱅크), <code>MACAB</code>(모든 뱅크)와 같이 지정된 수의 뱅크에서 MAC 연산을 수행하는 명령어.</li>
<li><strong>데이터 이동 명령어:</strong> <code>RDCP</code>(뱅크에서 전역 버퍼로 복사), <code>WRCP</code>(전역 버퍼에서 뱅크로 복사) 등 뱅크와 전역 버퍼 간의 데이터 전송을 위한 명령어.</li>
</ul>
</li>
<li><strong>계층 2: 호스트 통신을 위한 AiM ISR (Instruction Set Register):</strong> 호스트가 실제로 AiM 컨트롤러에 발행하는 명령어는 <strong>AiM ISR</strong>이라는 더 높은 수준의 추상화된 명령어 세트다. 이는 GitHub에 공개된 <code>aim_simulator</code>를 통해 그 구체적인 내용이 확인되었다.
<ul>
<li><code>MAC_ABK</code>(모든 뱅크에서 MAC 수행), <code>WR_GB</code>(전역 버퍼에 쓰기), <code>RD_MAC</code>(MAC 레지스터에서 읽기), <code>SYNC</code>(동기화) 등이 대표적인 ISR 명령어다.</li>
<li>호스트로부터 ISR 명령어를 수신한 AiM DRAM 시스템은 이를 해석하고, 명령어에 포함된 <code>opcode</code>와 <code>channel_mask</code> 필드를 기반으로 필요한 저수준 DRAM 명령어와 메모리 요청들을 생성하여 여러 채널에 걸쳐 실행을 '전개(unroll)'한다.</li>
</ul>
</li>
</ul>
<h3>데이터 관리 및 동기화</h3>
<p>AiM의 프로그래밍 모델은 PIM 레벨에서 레지스터 기반으로 동작한다. AiM DRAM 시스템은 연산을 위한 데이터를 임시 저장하기 위해 256비트 폭의 <strong>범용 레지스터(GPRs, General-Purpose Registers)</strong>를 포함한다. <code>WR_GB GPR_0</code>과 같은 명령어는 호스트가 접근 가능한 GPR의 데이터를 칩 내부의 전역 버퍼로 이동시키는 역할을 한다.</p>
<p>이러한 PIM 연산과 일반적인 메모리 접근이 혼재하는 환경에서는 데이터 위험(data hazard) 관리가 매우 중요하다. AiM 컨트롤러는 PIM 요청을 순서대로 처리하고, 한 종류의 요청(PIM 또는 일반 메모리)이 처리 중일 때는 다른 종류의 새로운 요청을 차단함으로써 데이터 일관성을 보장한다.</p>
<p>또한, 명시적인 동기화 메커니즘이 제공된다. <strong><code>SYNC</code></strong> 명령어는 일종의 장벽(barrier) 역할을 하여, 이전에 발행된 모든 PIM 연산이 컨트롤러에 의해 완료될 때까지 DRAM 시스템을 차단한다. 이는 <code>MAC_REG</code>나 <code>AF_REG</code>에 저장된 연산 결과를 GPR로 안전하게 읽어오기 위해 필수적인 기능이다.</p>
<h3>개발자 사용 편의성을 향한 길: 추상화 계층</h3>
<p>저수준의 DRAM 명령어와 ISR은 최종 애플리케이션 개발자가 직접 다루기에는 지나치게 복잡하고 비효율적이다. 따라서 AiM 기술의 광범위한 채택을 위해서는 고도로 추상화된 소프트웨어 스택이 반드시 필요하다. 일반적인 PIM 소프트웨어 스택은 다음과 같은 계층으로 구성된다.</p>
<ol>
<li><strong>PIM 디바이스 드라이버:</strong> 하드웨어와의 저수준 통신, 메모리 공간 할당 등 기본적인 장치 제어를 담당한다.</li>
<li><strong>PIM 런타임:</strong> 어떤 연산을 PIM으로 오프로드할지 결정하고, 해당 연산을 위한 AiM ISR 명령어 시퀀스를 생성하며, 메모리 사용을 관리한다.</li>
<li><strong>PIM 라이브러리:</strong> 행렬-벡터 곱셈과 같은 주요 연산을 위해 PIM에 최적화된 저수준 루틴(예: PIM-BLAS)을 제공한다.</li>
<li><strong>프레임워크 통합:</strong> PyTorch, TensorFlow와 같은 고수준 딥러닝 프레임워크와의 통합을 담당한다. 이는 프레임워크에 커스텀 연산자(custom operator)를 추가하거나, ONNX 런타임의 경우 <strong>AiM 실행 프로바이더(Execution Provider)</strong>를 구현하는 방식으로 이루어진다. 이를 통해 개발자는 익숙한 API를 사용하여 모델을 작성하면, 백엔드의 런타임이 자동으로 PIM 하드웨어로의 오프로딩을 처리하게 된다.</li>
</ol>
<p>한 가지 명확히 할 점은, <code>aimhubio</code>에서 제공하는 오픈소스 MLOps 도구인 <code>aim</code>과 SK 하이닉스의 AiM 기술은 전혀 다른 것이라는 점이다. 연구 자료에 포함된 <code>aim</code>의 PyTorch 예제 코드는 MLOps 도구의 사용법을 보여줄 뿐, SK 하이닉스 하드웨어와의 통합을 시연하는 것이 아니다. 실제 통합은 SK 하이닉스나 파트너사가 제공하는 전용 라이브러리를 통해 이루어질 것이다.</p>
<h2>성능, 효율성 및 경쟁력 분석</h2>
<p>SK 하이닉스의 GDDR6-AiM은 특정 AI 워크로드에서 기존 GPU 대비 압도적인 성능 및 전력 효율성 향상을 목표로 설계되었다. 실제 시연과 학술적 분석을 통해 이러한 주장의 타당성을 검증하고, 경쟁 PIM 아키텍처와의 비교를 통해 그 기술적 위상을 평가할 수 있다.</p>
<h3>기존 GPU 대비 성능 벤치마크</h3>
<p>SK 하이닉스는 GDDR6-AiM이 특정 연산에서 기존 방식보다 최대 <strong>16배</strong> 빠른 속도를 제공할 수 있다고 주장한다. 이러한 주장은 여러 AiM 칩을 탑재한 가속기 카드인 <strong>AiMX</strong> 시스템의 시연을 통해 구체화되었다. 메타(Meta)의 OPT-13B 언어 모델을 구동한 시연에서 AiMX 시스템은 기존 GPU 기반 시스템 대비 데이터 처리 시간을 <strong>10배 이상</strong> 단축하면서도 전력 소비는 <strong>5분의 1</strong> 수준으로 줄이는 놀라운 결과를 보여주었다.</p>
<p>학술 연구는 이러한 성능 우위를 보다 비용 효율적인 관점에서 분석한다. "TokenSim" 논문에서는 LLM 추론 과정을 연산 집약적인 '프리필(prefill)' 단계와 메모리 집약적인 '디코딩(decode)' 단계로 분리하는 시스템을 모델링했다. 이 시뮬레이션에 따르면, 총 8개의 가속기 슬롯이 있는 서버에서 5개의 NVIDIA A100 GPU를 구매할 예산으로, 프리필 단계에 1개의 A100 GPU를 할당하고 메모리 집약적인 디코딩 단계에 7개의 GDDR6-AiM(G6-Aim) 유닛을 배치하는 이종(heterogeneous) 구성을 채택할 경우, A100 GPU 5개로만 구성된 시스템과 <strong>유사한 처리량(throughput)</strong>을 달성하면서도 비용을 크게 절감할 수 있음이 나타났다. 이는 AiM이 범용 가속기가 아닌, LLM 디코딩과 같은 특정 메모리 병목 현상을 해결하는 데 특화된 '디코딩 가속기'로서 높은 비용 효율성을 가짐을 시사한다.</p>
<h3>경쟁 아키텍처 비교 분석: GDDR6-AiM vs. 삼성 HBM-PIM</h3>
<p>현재 상용 PIM 시장은 SK 하이닉스의 GDDR6-AiM과 삼성전자의 HBM-PIM(또는 FIMDRAM)이 양분하고 있다. 두 기술은 PIM이라는 공통된 목표를 추구하지만, 기반 기술과 아키텍처 설계에서 뚜렷한 차이를 보인다.</p>
<ul>
<li><strong>기반 메모리 기술:</strong> AiM은 그래픽 카드에 널리 사용되는 고속의 평면(planar) 메모리인 GDDR6를 기반으로 한다. 반면, 삼성의 HBM-PIM은 3D 스태킹 기술을 사용하여 극도로 넓은 버스 폭과 뛰어난 전력 효율성을 자랑하는 HBM2를 기반으로 한다. HBM은 주로 최고급 AI 가속기에 채택된다.</li>
<li><strong>연산 유닛 구조:</strong> AiM은 다이당 16개의 PU를 각 뱅크에 하나씩 독립적으로 배치하고 1 GHz로 구동한다. HBM-PIM은 '프로그래머블 컴퓨팅 유닛(PCU)'이라는 연산 장치를 두 개의 뱅크가 공유하는 구조이며, 300 MHz의 상대적으로 낮은 클럭으로 동작한다. 두 아키텍처 모두 16비트 부동소수점 연산(AiM은 BF16, HBM-PIM은 FP16)을 지원한다.</li>
<li><strong>성능 및 효율성 비교:</strong> "PIM-DL" 논문은 두 아키텍처의 직접적인 성능 비교를 제공한다. 두 기술 모두 순수 연산 능력(AiM ~1 TFLOPS, HBM-PIM ~1.2 TFLOPS)은 최신 GPU에 비해 제한적이다. 그러나 알고리즘-시스템 공동 최적화(예: LUT 기반 추론)를 적용했을 때, AiM 기반 시스템은 NVIDIA V100 GPU보다 최대 1.2배 높은 성능을 보인 반면, HBM-PIM 기반 시스템은 V100 성능의 39%에 그쳤다. 이는 해당 특정 구성에서 AiM의 더 높은 클럭 속도와 뱅크당 전용 PU 구조가 성능 우위로 작용했음을 시사한다.</li>
</ul>
<p>다음 표는 주요 AI 가속 아키텍처의 특징을 요약하여 비교한 것이다. 이 표는 여러 자료에 흩어져 있는 정보를 종합하여 각 아키텍처의 장단점을 명확히 보여주는 분석 도구 역할을 한다.</p>
<table>
<thead>
<tr>
<th>기능</th>
<th>고성능 GPU (예: NVIDIA A100)</th>
<th>SK 하이닉스 GDDR6-AiM</th>
<th>삼성 HBM-PIM (FIMDRAM)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>패러다임</strong></td>
<td>프로세서 중심 (Processor-Centric)</td>
<td>메모리 근접 처리 (PnM)</td>
<td>메모리 근접 처리 (PnM)</td>
</tr>
<tr>
<td><strong>기반 메모리 기술</strong></td>
<td>HBM2e / HBM3</td>
<td>GDDR6</td>
<td>HBM2</td>
</tr>
<tr>
<td><strong>외부 대역폭</strong></td>
<td>~2 TB/s</td>
<td>칩당 64 GB/s</td>
<td>스택당 ~410 GB/s</td>
</tr>
<tr>
<td><strong>내부 대역폭</strong></td>
<td>해당 없음 (모놀리식)</td>
<td>다이당 512 GB/s (칩당 1024 GB/s)</td>
<td>높음 (뱅크 레벨 병렬성 활용)</td>
</tr>
<tr>
<td><strong>연산 유닛</strong></td>
<td>수천 개의 CUDA/Tensor 코어</td>
<td>다이당 16개 PU (뱅크당 1개)</td>
<td>다이당 16개 PCU (2뱅크당 1개)</td>
</tr>
<tr>
<td><strong>연산 처리량</strong></td>
<td>>100 TFLOPS (혼합 정밀도)</td>
<td>칩당 1 TFLOPS (BF16)</td>
<td>스택당 ~1.2 TFLOPS (FP16)</td>
</tr>
<tr>
<td><strong>수치 정밀도</strong></td>
<td>FP64, FP32, TF32, FP16, INT8</td>
<td>BF16</td>
<td>FP16</td>
</tr>
<tr>
<td><strong>전력 소비</strong></td>
<td>높음 (예: 400W)</td>
<td>낮음 (1.25V 동작, 80% 절감 주장)</td>
<td>낮음 (기존 HBM 대비 70% 절감)</td>
</tr>
<tr>
<td><strong>프로그래밍 모델</strong></td>
<td>CUDA, OpenCL (성숙한 생태계)</td>
<td>확장된 DRAM 명령어, 호스트 주도 ISR</td>
<td>일반 메모리 명령어, FIM 모드</td>
</tr>
<tr>
<td><strong>주요 타겟</strong></td>
<td>범용, 연산 집약적 워크로드</td>
<td>메모리 집약적 (LLM 디코딩, GEMV)</td>
<td>메모리 집약적 (AI/ML, GEMV)</td>
</tr>
</tbody>
</table>
<h3>총 소유 비용(TCO) 및 달러당 성능</h3>
<p>PIM 기술의 가장 강력한 설득력은 순수 성능이 아닌 경제성, 즉 총 소유 비용(TCO)과 전력 효율성에서 나온다. "PIM Is All You Need" (CENT) 논문은 LLM 추론과 같이 메모리 집약적인 워크로드에서 GPU의 연산 자원이 심각하게 낭비되고 있으며, 이로 인해 높은 TCO가 발생한다고 지적한다. 사용자는 데이터를 기다리며 유휴 상태에 있는 비싼 연산 자원에 비용을 지불하고 있는 셈이다.</p>
<p>이 논문은 PIM과 CXL을 기반으로 한 GPU-Free 시스템(CENT)을 제안하며, 이러한 메모리 중심 시스템이 GPU 기반 시스템에 비해 <strong>달러당 5.2배 더 많은 토큰</strong>을 생성할 수 있다고 분석했다. 이는 단일 PIM 칩이 GPU의 최고 성능을 능가하지는 못하더라도, 비용 효율적이고 전력 효율적인 PIM 가속기로 구성된 시스템이 특정 워크로드에 대해 월등한 달러당 성능 및 와트당 성능을 제공할 수 있음을 의미한다.</p>
<h2>근본적인 과제와 아키텍처적 한계</h2>
<p>GDDR6-AiM과 같은 PIM 기술은 특정 영역에서 혁신적인 성능을 제공하지만, 범용 기술로 나아가기 위해서는 반드시 해결해야 할 근본적인 과제와 아키텍처적 한계를 안고 있다. 이러한 한계는 PIM 기술의 본질적인 설계 제약, 확장성 문제, 그리고 시스템 통합의 복잡성에서 기인한다.</p>
<h3>내재된 PIM 설계 제약</h3>
<ul>
<li><strong>면적/전력/발열의 트레이드오프:</strong> PIM의 가장 큰 제약은 로직 회로를 DRAM 공정 위에 구현해야 한다는 점에서 발생한다. DRAM 공정은 메모리 셀의 집적도에 최적화되어 있어, 로직 회로를 위한 CMOS 공정에 비해 속도가 느리고 집적도가 낮다. 이로 인해 PIM 설계는 연산 유닛의 면적과 전력 소모에 극심한 제약을 받게 되며, 완전한 기능의 프로세서 코어 대신 최소한의 연산 유닛(예: MAC, 버퍼)만을 탑재할 수밖에 없다. SK 하이닉스는 AiM의 로직이 전체 다이 면적의 약 20%를 차지한다고 밝혔는데, 이는 상당한 면적 오버헤드다. 또한, 연산 유닛에서 발생하는 열은 열에 취약한 DRAM 셀의 성능에 악영향을 줄 수 있어 정교한 열 관리 기술이 요구된다.</li>
<li><strong>워크로드 특화:</strong> 이러한 물리적 제약의 직접적인 결과로, PIM은 범용 가속기가 될 수 없다. PIM은 산술 강도(arithmetic intensity)가 낮고 데이터 접근 패턴이 규칙적인 <strong>메모리 집약적 애플리케이션</strong>에만 효과적이다. 반대로, 연산 집약적인 작업에서는 강력한 연산 유닛을 갖춘 GPU가 훨씬 뛰어난 성능을 보인다.</li>
<li><strong>다중 피연산자 문제:</strong> PIM 아키텍처의 근본적인 한계 중 하나는 두 개 이상의 크고 재사용성이 낮은 피연산자를 갖는 연산을 효율적으로 처리하기 어렵다는 점이다. PIM 연산 유닛은 물리적으로 하나의 피연산자(예: 가중치 행렬)에만 '근접'할 수 있다. 다른 큰 피연산자는 여전히 호스트로부터 전송되어야 하므로, 이는 PIM의 대역폭 이점을 상쇄시킨다. 행렬-벡터 곱셈(GEMV)이 PIM에 이상적인 이유는 하나의 큰 행렬과 하나의 작은 벡터를 입력으로 받기 때문이며, 행렬-행렬 곱셈(GEMM)은 두 행렬이 모두 클 경우 PIM의 이점을 살리기 어렵다.</li>
</ul>
<h3>확장성 병목: 허브로서의 호스트</h3>
<p>단일 PIM 칩은 강력하지만, 여러 칩을 연결하여 <strong>AiMX 카드</strong>와 같은 시스템으로 확장할 때 새로운 병목이 발생한다. 현재 상용화된 PIM 아키텍처들은 PIM 칩(또는 노드) 간의 직접적인 통신 채널을 제공하지 않는다. AiM의 성능이 각 뱅크의 독립적인 병렬 처리에서 나오는 만큼, 이는 구조적인 한계이기도 하다. 즉, 단일 칩 성능을 극대화하는 설계(독립된 병렬 뱅크)가 역설적으로 다중 칩 통신 병목의 원인이 되는 것이다.</p>
<p>모든 PIM 노드 간 통신은 반드시 <strong>호스트 CPU를 경유</strong>해야 한다. 예를 들어, 하나의 AiM 칩에서 다른 AiM 칩으로 데이터를 전달하려면, 데이터를 첫 번째 칩에서 호스트로 읽어온 다음, 호스트에서 두 번째 칩으로 다시 써야 한다. 이러한 중앙 집중적이고 간접적인 통신 방식은 AllReduce나 All-to-All과 같은 집합적 통신(collective communication)이 필수적인 애플리케이션에서 심각한 성능 저하를 유발하며, PIM 시스템의 확장성을 근본적으로 제한한다. 심지어 PIM 노드의 수를 늘릴수록 이 통신 오버헤드 때문에 전체 성능이 오히려 감소하는 현상이 발생할 수도 있다.</p>
<h3>캐시 일관성 문제</h3>
<p>캐시 일관성(Cache Coherence) 문제는 PIM 기술이 투명하고 광범위하게 채택되는 데 있어 가장 큰 장벽 중 하나다. 호스트 CPU와 PIM 장치가 메모리를 공유할 때, 동일한 데이터의 복사본이 여러 곳에 존재할 수 있다. 예를 들어, CPU 캐시와 PIM이 연산하는 주 메모리에 같은 데이터가 있을 수 있다. 이때 한쪽에서 데이터를 수정하면 다른 한쪽의 데이터는 유효하지 않은 '오래된(stale)' 데이터가 되어 데이터 불일치 문제를 야기한다.</p>
<p>기존의 스누핑(snooping) 기반 캐시 일관성 프로토콜은 PIM과 같은 오프칩(off-chip) 장치로 확장될 경우, 프로토콜 메시지로 인해 메모리 버스에 과도한 트래픽을 유발하여 새로운 병목이 될 수 있다. 이 때문에 초기 PIM 시스템들은 프로그래머가 명시적으로 캐시를 비우거나(flushing), 캐시를 우회하는 방식을 사용해야 했다. 이는 복잡하고 오류 발생 가능성이 높아 PIM 프로그래밍을 어렵게 만드는 주된 요인이다. PIM을 위한 효율적이고 오버헤드가 적은 하드웨어 캐시 일관성 메커니즘의 부재는 여전히 중요한 연구 과제로 남아있다.</p>
<p>이러한 하드웨어와 소프트웨어 간의 문제는 일종의 악순환을 형성한다. 하드웨어 제조사는 성숙한 소프트웨어 생태계가 없기 때문에 PIM 간 인터커넥트나 하드웨어 일관성 지원과 같은 복잡한 기능을 추가하는 것을 주저한다. 반대로 소프트웨어 개발자들은 표준화된 기능이 부족하고 널리 보급되지 않은 하드웨어를 위해 PIM 특화 최적화에 막대한 투자를 하기를 꺼린다. LLM이라는 '킬러 앱'의 등장과 CXL이라는 표준 인터커넥트의 부상은 바로 이 오랜 악순환을 끊을 수 있는 핵심적인 두 가지 동력이다.</p>
<h2>미래 전망: PIM, CXL, 그리고 분산형 데이터센터</h2>
<p>GDDR6-AiM은 PIM 기술의 현재를 보여주는 중요한 제품이지만, SK 하이닉스와 업계의 비전은 이미 그 다음 단계를 향하고 있다. PIM 기술의 근본적인 한계를 극복하고 그 적용 범위를 넓히기 위해, 차세대 인터커넥트 기술인 CXL과의 융합이 핵심 전략으로 부상하고 있다.</p>
<h3>SK 하이닉스의 제품 및 기술 로드맵</h3>
<p>SK 하이닉스는 GDDR6-AiM을 기반으로 한 <strong>AiMX 가속기 카드</strong>를 통해 생성형 AI 시장을 직접 공략하는 동시에, PIM 기술 포트폴리오를 다각화하고 있다.</p>
<ul>
<li><strong>온디바이스 AI를 위한 LPDDR5-AiM:</strong> 데이터센터를 넘어, 모바일 기기를 위한 <strong>LPDDR5-AiM</strong> 기술을 개발하고 있다. 모바일 환경의 AI 워크로드는 배치 크기가 작아 메모리 집약적인 특성을 보이므로, 저전력 PIM 기술의 이상적인 적용처가 될 수 있다.</li>
<li><strong>CXL 기반 컴퓨팅 메모리 모듈 (CMM-Ax):</strong> SK 하이닉스 로드맵의 가장 중요한 방향은 CXL 기술을 활용하는 것이다. <strong>CMM-Ax (CXL Memory Module-Accelerator)</strong>는 CXL 인터페이스에 연산 기능을 통합한 제품으로, PIM의 확장성과 유연성을 획기적으로 개선할 것으로 기대된다.</li>
<li><strong>생태계 구축을 위한 표준화 노력:</strong> 경쟁사인 삼성전자와 함께 <strong>LPDDR6-PIM</strong> 기술의 표준화를 추진하는 것은 주목할 만한 행보다. 이는 특정 기업에 종속되지 않는, 보다 개방적이고 상호 운용 가능한 PIM 생태계를 구축하여 기술 채택을 가속화하려는 전략적 의도로 풀이된다.</li>
</ul>
<h3>CXL (Compute Express Link)의 역할</h3>
<p>CXL은 PIM 기술이 데이터센터의 주류 기술로 도약하기 위해 반드시 필요한 '잃어버린 고리'와 같다. PCIe 물리 계층을 기반으로 하는 CXL은 고대역폭, 저지연, 그리고 캐시 일관성을 지원하는 개방형 인터커넥트 표준이다.</p>
<ul>
<li><strong>용량 문제 해결:</strong> CXL.mem 프로토콜은 서버의 메모리 용량을 테라바이트급으로 손쉽게 확장할 수 있게 해준다. 이는 모델 파라미터와 KV 캐시 크기가 기하급수적으로 증가하는 LLM 환경에서, 단일 가속기 카드의 메모리 용량 한계를 극복하는 데 필수적이다.</li>
<li><strong>확장성 병목 해결:</strong> CXL 2.0 이상 버전은 스위칭 기능을 도입하여 CXL 장치 간의 직접적인 P2P(Peer-to-Peer) 통신을 지원한다. 이는 여러 PIM 장치가 호스트 CPU를 거치지 않고 CXL 패브릭을 통해 직접 데이터를 교환할 수 있게 함으로써, 앞서 지적된 PIM의 확장성 병목을 근본적으로 해결할 수 있다.</li>
<li><strong>분산형 데이터센터 구현:</strong> CXL은 메모리, 연산, 가속기 등의 자원을 물리적으로 분리하고 필요에 따라 동적으로 조합하여 사용하는 분산형(disaggregated) 데이터센터의 핵심 기술이다. CMM-Ax와 같은 PIM 기반 CXL 메모리는 이러한 환경에서 고대역폭 메모리 중심 연산 자원 풀(pool)로서 완벽하게 기능할 수 있다.</li>
</ul>
<h3>차세대 시스템의 청사진: CENT 아키텍처</h3>
<p>ASPLOS 2025 학회에서 발표된 "PIM Is All You Need" (CENT) 논문은 AiM과 같은 PIM 기술이 CXL과 결합하여 어떻게 진화할 수 있는지에 대한 구체적인 청사진을 제시한다.</p>
<ul>
<li><strong>계층적 PIM-PNM 구조:</strong> CENT는 순수한 PIM 아키텍처를 넘어 계층적 구조를 제안한다. 가장 빈번하고 단순한 연산(예: MAC)은 DRAM 다이 내부에 위치한 <strong>뱅크 근접 PU (PIM)</strong>가 처리하여 효율을 극대화한다. 반면, Softmax나 나눗셈과 같이 더 복잡하거나 다양한 연산은 CXL 컨트롤러 칩에 위치한 더 강력한 <strong>메모리 근접 처리 장치 (PNM)</strong>가 담당한다. 특히, 이 PNM 유닛에는 유연성을 확보하기 위해 프로그래밍 가능한 <strong>RISC-V 코어</strong>가 포함된다. 이러한 이기종 계층 구조는 극단적인 효율성과 프로그래밍 유연성 사이의 균형을 맞추는 성숙한 아키텍처적 비전을 보여준다.</li>
<li><strong>CXL 기반 통신:</strong> CENT 시스템은 CXL 스위치를 통해 여러 CXL 장치들을 연결하며, 장치 간 통신은 호스트를 완전히 우회하여 P2P로 이루어진다. 더 나아가, 효율적인 집합적 통신을 위해 <code>BCAST_CXL</code>과 같은 커스텀 CXL 명령어를 제안한다. 이는 PIM의 확장성 병목 문제를 직접적으로 해결하는 설계다.</li>
</ul>
<p>결론적으로, CENT 아키텍처는 PIM의 논리적인 진화 방향을 제시한다. 즉, 핵심 워크로드(GEMV)에 대해서는 초특화된 PIM 유닛의 효율성을 유지하면서, 유연성을 위해 프로그래밍 가능한 PNM 코어를 추가하고, CXL을 통해 확장성 문제를 해결하는 것이다.</p>
<h2>결론 및 전략적 제언</h2>
<h3>최종 종합: 선구적이지만 특화된 솔루션</h3>
<p>본 보고서의 분석을 종합하면, SK 하이닉스의 GDDR6-AiM은 PIM 기술의 상업적 잠재력을 입증한 기념비적인 제품이다. 이 기술의 아키텍처는 AI 워크로드의 핵심인 GEMV 연산에서 발생하는 메모리 병목 현상을 해결하기 위한 우아한 해법이며, 와트당 성능과 총 소유 비용(TCO) 측면에서 극적인 개선을 제공한다.</p>
<p>그러나 AiM의 강점은 동시에 약점이기도 하다. 극단적인 특화는 적용 가능한 워크로드를 제한하며, 현재의 아키텍처는 확장성과 프로그래밍 용이성 측면에서 범용 GPU를 대체하기 어려운 근본적인 한계를 가지고 있다. 따라서 GDDR6-AiM과 그 동시대 기술들은 메모리 중심 컴퓨팅이라는 최종 목적지가 아니라, 그곳으로 향하는 긴 여정의 중요한 이정표로 평가해야 한다.</p>
<h3>이해관계자를 위한 제언</h3>
<ul>
<li><strong>시스템 아키텍트를 위해:</strong> 메모리 집약적인 추론 작업, 특히 분산형 시스템 환경에서는 AiMX와 같은 PIM 기반 가속기 도입을 적극적으로 고려해야 한다. 평가 기준은 최고 연산 성능(peak FLOPS)이 아니라 TCO와 와트당 성능이 되어야 한다. 또한, 현재의 확장성 한계를 극복하기 위해 CXL 기반의 미래 로드맵을 염두에 둔 시스템 설계를 계획해야 한다.</li>
<li><strong>AI/ML 연구자 및 개발자를 위해:</strong> 기반 하드웨어의 특성을 이해하는 것이 중요하다. 가능하면 모델과 알고리즘을 GEMV와 같이 메모리 집약적인 기본 연산(primitive)을 최대한 활용하는 방향으로 구조화해야 한다. PIM 지원 시스템에서는 데이터 레이아웃과 태스크 스케줄링이 성능에 지대한 영향을 미치므로, 일반적인 GPU 프로그래밍의 추상화 계층 너머를 고려할 필요가 있다.</li>
<li><strong>산업계를 위해:</strong> SK 하이닉스와 삼성이 LPDDR6-PIM 표준화를 위해 협력하는 것은 매우 긍정적인 신호다. 견고한 소프트웨어 생태계를 구축하고 광범위한 기술 채택을 유도하기 위해서는 PIM 명령어 세트, 메모리 매핑, 일관성 인터페이스 등에 대한 업계 표준화 노력이 지속되어야 한다.</li>
</ul>
<h3>최종 전망: 메모리 중심의 미래</h3>
<p>PIM 기술이 CXL 및 이기종 설계와 융합하는 현재의 흐름은, 메모리가 더 이상 수동적인 주변 장치가 아니라 컴퓨팅 패브릭의 능동적이고 지능적인 핵심 구성 요소가 되는 미래를 가리키고 있다. GDDR-AiM, LPDDR-AiM, 그리고 CMM-Ax에 이르는 포트폴리오를 갖춘 SK 하이닉스는 이러한 변화의 중심에서 핵심적인 역할을 수행할 준비가 되어 있으며, 메모리 중심 컴퓨팅 시대를 선도할 유력한 주자 중 하나로 자리매김하고 있다.</p>
</body>
</html>

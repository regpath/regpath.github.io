<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>모두의 AI 케인의 Agent로 완성하는 RAG: 데이터 별 아키텍처 설계를 중심으로</title>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f4f4f4;
            color: #333;
        }
        .container {
            max-width: 900px;
            margin: auto;
            background: #fff;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 0 15px rgba(0,0,0,0.1);
        }
        h1, h2, h3 {
            color: #0056b3;
            border-bottom: 2px solid #0056b3;
            padding-bottom: 5px;
        }
        h1 {
            text-align: center;
            font-size: 2.5em;
        }
        h2 {
            font-size: 2em;
            margin-top: 40px;
        }
        h3 {
            font-size: 1.5em;
            margin-top: 30px;
            border-bottom: 1px solid #ddd;
        }
        hr {
            border: 0;
            height: 1px;
            background: #ddd;
            margin: 40px 0;
        }
        p, li {
            font-size: 1.1em;
        }
        code {
            background-color: #eee;
            padding: 0.2em 0.4em;
            margin: 0;
            font-size: 0.9em;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
        }
        pre {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 5px;
            overflow-x: auto;
            position: relative;
        }
        pre code {
            background: none;
            color: inherit;
            padding: 0;
            font-size: 1em;
        }
        .code-title {
            font-weight: bold;
            margin-bottom: 10px;
            display: block;
            color: #888;
        }
        strong {
            color: #d9534f;
        }
        blockquote {
            background: #f9f9f9;
            border-left: 5px solid #ccc;
            margin: 1.5em 10px;
            padding: 0.5em 10px;
        }
        blockquote p {
            display: inline;
        }
        .note {
            background-color: #e7f3fe;
            border-left: 6px solid #2196F3;
            padding: 15px;
            margin-top: 20px;
        }
        .warning {
            background-color: #fffbe6;
            border-left: 6px solid #ffc107;
            padding: 15px;
            margin-top: 20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>📘 모두의 AI 케인의 Agent로 완성하는 RAG: 데이터 별 아키텍처 설계를 중심으로</h1>

        <div class="note">
            <p><strong>참고:</strong> 이 교재는 Fastcampus의 "모두의 AI 케인의 Agent로 완성하는 RAG" 강의의 공식 교육과정소개서를 기반으로 제작되었습니다. 원본 GitHub 리포지터리 접근이 불가능하여, 공개된 최신 기술 문서와 데이터셋을 바탕으로 핵심 개념과 실습 코드를 재구성하였습니다. 따라서 일부 코드와 데이터셋은 실제 강의 내용과 다를 수 있으나, 학습 목표 달성을 위해 동일한 수준의 기술과 유사한 데이터 구조를 사용하도록 설계되었습니다.</p>
        </div>

        <hr>

        <h2>CH 01. LLM의 한계와 가능성, 그리고 RAG 🚀</h2>

        <h3>학습 목표</h3>
        <ul>
            <li>거대 언어 모델(LLM)의 최신 발전 동향 3가지를 이해합니다.</li>
            <li>LLM이 가진 본질적인 한계점(환각, 최신성 부족)을 설명할 수 있습니다.</li>
            <li>RAG(Retrieval-Augmented Generation)가 왜 LLM의 한계를 극복하기 위한 필수 기술로 주목받는지 이해합니다.</li>
        </ul>

        <h3>이론 설명: LLM의 눈부신 발전과 그림자</h3>
        <p>2024년, 거대 언어 모델(LLM)은 3가지 주요 방향으로 폭발적인 발전을 거듭하고 있습니다.</p>
        <ol>
            <li><strong>멀티모달 (Multimodal):</strong> 텍스트뿐만 아니라 이미지, 소리, 영상을 이해하고 생성하는 능력입니다. OpenAI의 GPT-4o, Google의 Gemini가 대표적입니다.</li>
            <li><strong>장문 컨텍스트 (Long Context):</strong> 한 번에 처리할 수 있는 정보의 양이 수만, 수십만 토큰을 넘어 수백만 토큰(Anthropic의 Claude 3)에 이르며, 책 한 권 분량의 정보를 한 번에 이해하고 분석할 수 있게 되었습니다.</li>
            <li><strong>추론 (Reasoning):</strong> 단순히 정보를 요약하는 것을 넘어, 복잡한 문제 해결을 위한 계획을 수립하고, 여러 도구를 활용하여 스스로 문제를 해결하는 '에이전트(Agent)'로서의 가능성을 보여주고 있습니다.</li>
        </ol>
        <p>하지만 이러한 발전에도 불구하고 LLM은 두 가지 치명적인 한계를 가지고 있습니다.</p>
        <ul>
            <li><strong>환각 (Hallucination):</strong> 학습 데이터에 없는 내용에 대해 질문받거나, 사실과 다른 정보를 그럴듯하게 꾸며내어 답변하는 문제입니다. 이는 LLM이 '이해'하는 것이 아니라 학습된 데이터의 '통계적 패턴'을 기반으로 가장 확률 높은 단어를 예측하기 때문에 발생합니다.</li>
            <li><strong>지식 단절 (Knowledge Cut-off):</strong> LLM은 특정 시점까지의 데이터로 학습됩니다. 따라서 그 이후에 발생한 최신 정보나, 기업 내부의 비공개 데이터와 같은 특정 도메인의 지식에 대해서는 알지 못합니다.</li>
        </ul>
        <p>이러한 한계를 해결하기 위해 등장한 기술이 바로 <strong>RAG(Retrieval-Augmented Generation)</strong>입니다. RAG는 LLM이 답변을 생성(Generation)하기 전에, 질문과 관련된 정확한 정보를 외부 데이터 소스에서 검색(Retrieval)하여 그 내용을 참고하도록 하는 방식입니다. 이는 마치 우리가 시험을 볼 때 '오픈북'을 참고하는 것과 같습니다. LLM이라는 똑똑한 학생에게 최신 정보와 정확한 데이터가 담긴 '참고서'를 쥐여주는 것입니다.</p>

        <hr>

        <h2>CH 02. RAG의 진화: Modular, Agentic, and Beyond 🧠</h2>
        
        <h3>학습 목표</h3>
        <ul>
            <li>기본적인 RAG(Naive RAG)의 작동 방식을 이해합니다.</li>
            <li>최신 RAG의 3가지 발전 방향(보완, 확장, 대체)을 이해합니다.</li>
            <li>Modular RAG, Agentic RAG, Graph RAG 등 고급 RAG 아키텍처의 개념을 설명할 수 있습니다.</li>
        </ul>

        <h3>이론 설명: RAG, 더 똑똑해지는 방법</h3>
        <p>초기의 RAG는 '검색 -> 생성'의 단순한 파이프라인이었습니다. 하지만 더 복잡한 질문에 답하고, 더 높은 품질의 답변을 생성하기 위해 RAG는 끊임없이 진화하고 있습니다.</p>
        
        <h4>1. 보완 (Augmentation): RAG 파이프라인 강화하기</h4>
        <p>기존 RAG 파이프라인의 각 단계를 정교하게 다듬는 방식입니다.</p>
        <ul>
            <li><strong>Modular RAG:</strong> 검색(Retrieval)과 생성(Generation) 사이사이에 새로운 모듈을 추가합니다. 예를 들어, 사용자의 복잡한 질문을 여러 개의 간단한 질문으로 나누는 쿼리 변환(Query Transformation) 모듈, 검색된 문서의 순위를 재조정하는 리랭킹(Re-ranking) 모듈, 생성된 답변이 검색된 내용에 기반했는지 검증하는 답변 검증(Answer Validation) 모듈 등을 추가하여 전체 시스템의 성능을 높입니다.</li>
            <li><strong>Agentic RAG:</strong> LLM이 단순히 주어진 정보를 바탕으로 답변만 생성하는 수동적인 역할을 넘어, 스스로 판단하고 행동하는 '에이전트'가 됩니다. 예를 들어, LLM은 사용자의 질문을 분석하여 어떤 정보를 검색해야 할지 스스로 결정하고(Self-querying), 검색 결과가 충분하지 않으면 다른 키워드로 다시 검색을 시도하거나(Step-back prompting), 여러 도구(Tool-use)를 활용해 정보를 종합합니다. <strong>LangGraph</strong>는 이러한 에이전트의 복잡한 작업 흐름을 상태 그래프(State Graph) 형태로 설계하고 구현하는 데 최적화된 라이브러리입니다.</li>
        </ul>

        <h4>2. 확장 (Expansion): RAG의 능력을 넓히다</h4>
        <ul>
            <li><strong>Multimodal RAG:</strong> 텍스트뿐만 아니라 이미지, 표, 차트 등 다양한 형태의 데이터를 검색하고, 이를 종합하여 답변을 생성합니다. 예를 들어, "작년 4분기 매출 실적 보고서의 핵심 내용을 요약하고, 관련 성장률 차트를 보여줘"라는 요청에 텍스트 요약과 함께 이미지 차트를 함께 제시할 수 있습니다.</li>
            <li><strong>Graph RAG:</strong> 기존의 키워드나 벡터 유사도 검색을 넘어, 데이터 간의 '관계'를 활용하는 방식입니다. 지식 그래프(Knowledge Graph)를 사용하여 "A 회사의 자회사이면서 반도체 사업을 하는 곳은 어디야?"와 같이 복잡한 관계 추론이 필요한 질문에 더 정확하게 답변할 수 있습니다.</li>
        </ul>

        <h4>3. 대체 (Replacement): RAG의 새로운 패러다임</h4>
        <p><strong>KAG(Knowledge-Augmented Generation)</strong>나 <strong>CAG(Context-Augmented Generation)</strong>와 같이, 상황에 따라 RAG의 일부 구성 요소를 다른 방식으로 대체하거나 LLM의 내부 지식을 더 적극적으로 활용하는 연구도 진행되고 있습니다.</p>

        <hr>

        <h2>CH 03. 실전 RAG를 위한 환경 구축 및 기본기 🛠️</h2>

        <h3>학습 목표</h3>
        <ul>
            <li>Docker를 이용해 실습 환경을 구축할 수 있습니다.</li>
            <li>다양한 문서(PDF, Word, PPT, CSV)에서 텍스트를 추출(Extract)할 수 있습니다.</li>
            <li>추출된 텍스트를 의미 있는 단위로 분할(Chunking)하는 기법을 이해하고 적용할 수 있습니다.</li>
            <li>분할된 텍스트를 임베딩하고 Vector DB(Qdrant)에 저장(Load)할 수 있습니다.</li>
        </ul>
        
        <h3>실습 환경 구축</h3>
        <p>안정적이고 재현 가능한 실습 환경을 위해 Docker를 사용합니다. 아래 <code>Dockerfile</code>과 <code>docker-compose.yml</code> 파일을 프로젝트 루트에 생성합니다.</p>
        
        <span class="code-title">Dockerfile</span>
        <pre><code># Python 3.10을 기반 이미지로 사용
FROM python:3.10-slim

# 작업 디렉토리 설정
WORKDIR /app

# 필요한 패키지 설치
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 현재 디렉토리의 모든 파일을 컨테이너의 /app 디렉토리로 복사
COPY . .

# Jupyter Lab 실행
CMD ["jupyter", "lab", "--ip=0.0.0.0", "--port=8888", "--allow-root", "--no-browser", "--LabApp.token=''"]
</code></pre>

        <span class="code-title">docker-compose.yml</span>
        <pre><code>version: '3.8'
services:
  rag_app:
    build: .
    container_name: rag_project_container
    ports:
      - "8888:8888"  # Jupyter Lab
      - "6333:6333"  # Qdrant
    volumes:
      - .:/app
  
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant_db
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./qdrant_storage:/qdrant/storage
</code></pre>
        <p>터미널에서 <code>docker-compose up -d --build</code> 명령을 실행하여 실습 환경을 시작합니다.</p>

        <h3>실습 1: 문서 로드 및 파싱 (Extract & Transform)</h3>
        <p>다양한 형식의 문서에서 텍스트를 추출하고, LLM이 이해하기 좋은 단위로 자르는 과정입니다.</p>
        
        <h4>1. 문서 파싱 라이브러리 (Extractor)</h4>
        <p>LLM 애플리케이션 개발에서는 <code>LlamaParse</code>나 <code>Upstage Document AI</code>와 같이 표나 이미지를 포함한 복잡한 문서를 Markdown이나 JSON 형식으로 변환해주는 API가 매우 유용합니다. 이러한 API는 복잡한 문서 구조를 LLM이 더 잘 이해하도록 돕습니다.</p>
        
        <span class="code-title">Python Code: LlamaParse를 이용한 PDF 파싱</span>
        <pre><code class="language-python">
import llama_parse

# LlamaParse API 키 설정 (사전 발급 필요)
# os.environ["LLAMA_CLOUD_API_KEY"] = "llx-..."

# 파서 객체 생성
parser = llama_parse.LlamaParse(
    result_as_markdown=True, # 결과를 Markdown으로 받기
    verbose=True
)

# 파일 로드 및 파싱 실행 (비동기)
documents = await parser.aload_data("./data/sample_report.pdf")

# 파싱 결과 확인
print(documents[0].get_content())
        </code></pre>

        <h4>2. 텍스트 분할 (Chunking)</h4>
        <p>LLM이 한 번에 처리할 수 있는 컨텍스트 길이는 제한되어 있습니다. 따라서 긴 문서를 의미 있는 단위의 작은 덩어리(chunk)로 나누는 과정이 필수적입니다. 단순히 글자 수로 자르는 것보다, 문장이나 단락의 경계를 고려하는 <code>RecursiveCharacterTextSplitter</code>가 효과적입니다.</p>
        
        <span class="code-title">Python Code: RecursiveCharacterTextSplitter 사용</span>
        <pre><code class="language-python">
from langchain.text_splitter import RecursiveCharacterTextSplitter

# 분할기 객체 생성
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,    # 각 청크의 최대 크기
    chunk_overlap=200,  # 청크 간 중복되는 글자 수
    length_function=len,
    is_separator_regex=False,
)

# 문서 내용을 청크로 분할
chunks = text_splitter.split_text(documents[0].get_content())

print(f"Original document has {len(documents[0].get_content())} characters.")
print(f"Split into {len(chunks)} chunks.")
print("First chunk:", chunks[0])
        </code></pre>
        
        <h3>실습 2: 임베딩 및 Vector DB 저장 (Load)</h3>
        <p>분할된 텍스트 청크를 숫자 벡터(Embedding)로 변환하여, 벡터 간의 유사도를 빠르게 계산할 수 있는 Vector DB에 저장합니다.</p>
        
        <span class="code-title">Python Code: Qdrant에 데이터 저장</span>
        <pre><code class="language-python">
from langchain_openai import OpenAIEmbeddings
from langchain_qdrant import Qdrant
from qdrant_client import QdrantClient

# 임베딩 모델 로드 (OpenAI)
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# Qdrant 클라이언트 연결
client = QdrantClient(host="qdrant", port=6333)

# Qdrant Vector Store 객체 생성 및 데이터 저장
# 이 과정에서 LangChain이 내부적으로 chunks를 임베딩하고 Qdrant에 업로드합니다.
collection_name = "my_document_collection"
qdrant_store = Qdrant.from_texts(
    texts=chunks,
    embedding=embeddings,
    collection_name=collection_name,
    client=client
)

print(f"Successfully created and populated '{collection_name}' in Qdrant.")
        </code></pre>
        
        <hr>

        <h2>CH 04. RAG 실전에 도전하기: 데이터 유형별 아키텍처 설계 🏗️</h2>
        
        <h3>학습 목표</h3>
        <ul>
            <li>다양한 데이터(금융, 의료, 커머스 등)의 특성을 이해하고, 그에 맞는 RAG 아키텍처를 설계할 수 있습니다.</li>
            <li>각 시나리오에 맞는 공개 데이터셋을 찾고 전처리하는 방법을 학습합니다.</li>
            <li>대체 데이터셋을 생성하고 활용하는 방법을 익힙니다.</li>
        </ul>

        <h3>시나리오 1: 금융 공시 보고서 기반 Q&A 📈</h3>
        <p><strong>데이터 특성:</strong> 반정형 데이터. 복잡한 표, 재무제표, 텍스트가 혼재되어 있습니다. XBRL, PDF 등 다양한 형식이 존재하며, 정확한 숫자와 맥락 파악이 중요합니다.</p>
        <p><strong>아키텍처 설계:</strong>
            <ol>
                <li><strong>파싱 강화:</strong> <code>LlamaParse</code>나 <code>Upstage Document AI</code>를 사용하여 PDF 내의 표와 텍스트를 정확하게 마크다운 형식으로 변환합니다.</li>
                <li><strong>멀티 벡터 검색:</strong> 작은 청크는 임베딩하여 유사도 검색에 사용하고, 해당 청크가 속한 더 큰 원본 청크(부모 청크)를 함께 저장합니다. 검색 시에는 작은 청크로 유사도를 찾고, LLM에게는 맥락 파악이 용이한 부모 청크를 함께 전달합니다(Parent Document Retriever).</li>
                <li><strong>에이전트 활용:</strong> "A 회사의 2023년 대비 2024년 매출 성장률은?"과 같은 질문은 '2023년 매출'과 '2024년 매출'을 각각 검색하고, 그 결과를 바탕으로 계산하는 다단계 추론이 필요합니다. LangGraph를 이용한 에이전트를 설계하여 이러한 복합적인 질문을 해결합니다.</li>
            </ol>
        </p>

        <h4>데이터셋 처리</h4>
        <div class="warning">
            <p><strong>원본 데이터셋:</strong> 강의에서는 특정 경로(예: 구글 드라이브)를 통해 제공되는 사전 처리된 공시 보고서 파일을 사용할 수 있습니다.</p>
        </div>
        
        <span class="code-title">Python Code: [대체 데이터셋] SEC EDGAR 데이터 활용</span>
        <p>미국 증권거래위원회(SEC)는 EDGAR 시스템을 통해 기업의 재무 데이터를 공개합니다. <code>sec-api</code>와 같은 라이브러리를 사용하면 이를 쉽게 가져올 수 있습니다.</p>
        <pre><code class="language-python">
# pip install sec-api
from sec_api import QueryApi

# SEC API 키 설정
# queryApi = QueryApi(api_key="YOUR_API_KEY")
#
# # Apple(AAPL)의 10-K 보고서(연차 보고서) 검색
# query = {
#   "query": { "query_string": {
#       "query": "ticker:AAPL AND formType:\"10-K\""
#     } },
#   "from": "0",
#   "size": "1",
#   "sort": [{ "filedAt": { "order": "desc" } }]
# }
#
# filings = queryApi.get_filings(query)
# report_url = filings['filings'][0]['linkToFilingDetails']
#
# print(f"Found latest 10-K report URL: {report_url}")
# # 이 URL의 PDF 파일을 다운로드하여 LlamaParse로 파싱하는 과정을 진행합니다.
        </code></pre>

        <h3>시나리오 2: 멀티모달 의류 검색 👕👖</h3>
        <p><strong>데이터 특성:</strong> 이미지와 텍스트(상품 설명, 카테고리, 속성)가 결합된 멀티모달 데이터입니다.</p>
        <p><strong>아키텍처 설계:</strong>
            <ol>
                <li><strong>멀티모달 임베딩:</strong> CLIP과 같은 모델을 사용하여 이미지와 텍스트를 동일한 벡터 공간에 임베딩합니다. 이를 통해 "파란색 반팔 티셔츠"라는 텍스트 쿼리로 관련 이미지를 검색하거나, 특정 이미지와 유사한 스타일의 다른 상품을 찾는 것이 가능해집니다.</li>
                <li><strong>메타데이터 필터링:</strong> 벡터 검색과 함께 상품의 속성(예: '카테고리: 상의', '색상: 파랑')을 메타데이터로 저장합니다. Qdrant와 같은 Vector DB는 벡터 유사도 검색과 동시에 이러한 메타데이터를 필터링하는 기능을 제공하여, "상의 중에서 파란색인 상품을 찾아줘"와 같은 정교한 검색을 가능하게 합니다.</li>
            </ol>
        </p>

        <h4>데이터셋 처리</h4>
        <div class="warning">
            <p><strong>원본 데이터셋:</strong> 강의에서는 특정 경로를 통해 제공되는 패션 상품 이미지 및 메타데이터 파일을 사용할 수 있습니다.</p>
        </div>

        <span class="code-title">Python Code: [대체 데이터셋] Kaggle "Fashion Product Images" 활용</span>
        <p>Kaggle의 공개 데이터셋을 사용하여 실습을 진행할 수 있습니다. <code>opendatasets</code> 라이브러리를 사용하면 쉽게 데이터를 다운로드할 수 있습니다.</p>
        <pre><code class="language-python">
# pip install opendatasets
import opendatasets as od
import pandas as pd

# 데이터셋 다운로드 (Kaggle API 설정 필요)
dataset_url = 'https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-dataset'
od.download(dataset_url)

# 메타데이터 로드
df_styles = pd.read_csv('./fashion-product-images-dataset/styles.csv', on_bad_lines='skip')

# 이미지 경로와 메타데이터 결합
df_styles['image_path'] = df_styles['id'].apply(lambda x: f'./fashion-product-images-dataset/images/{x}.jpg')

# 데이터 샘플 확인
print(df_styles[['image_path', 'masterCategory', 'subCategory', 'articleType', 'productDisplayName']].head())

# 이후 df_styles의 각 행에 대해 이미지와 텍스트 설명을 멀티모달 임베딩하여 Vector DB에 저장합니다.
        </code></pre>

        <h3>시나리오 3: 의료 Q&A 🩺</h3>
        <p><strong>데이터 특성:</strong> 전문 용어가 많고, 정확성이 극도로 중요합니다. 논문, 진료 기록, 의학 교과서 등 신뢰할 수 있는 소스 기반의 답변이 필수적입니다.</p>
        <p><strong>아키텍처 설계:</strong>
            <ol>
                <li><strong>하이브리드 검색:</strong> 벡터 검색(의미 기반)과 키워드 검색(용어 정확도)을 결합하여 사용합니다. '인슐린 저항성'과 같은 전문 용어는 키워드 검색이 더 정확하게 찾을 수 있습니다.</li>
                <li><strong>리랭킹 모델 적용:</strong> 초기 검색된 여러 문서들을 질문과의 관련성이 높은 순으로 다시 정렬하는 리랭킹(Re-ranking) 단계를 추가하여, LLM에게 가장 중요한 정보를 우선적으로 제공합니다.</li>
                <li><strong>답변 검증 및 출처 제시:</strong> 생성된 답변이 어떤 문서를 근거로 했는지 반드시 출처(Citation)를 함께 제시하여 신뢰성을 높입니다. RAGAS와 같은 평가 프레임워크를 사용하여 답변의 사실성(Faithfulness)을 검증합니다.</li>
            </ol>
        </p>

        <h4>데이터셋 처리</h4>
        <div class="warning">
            <p><strong>원본 데이터셋:</strong> 강의에서는 특정 경로를 통해 제공되는 가상의 환자 데이터 또는 의료 관련 텍스트 파일을 사용할 수 있습니다.</p>
        </div>

        <span class="code-title">Python Code: [대체 데이터셋] Hugging Face "PubMedQA" 활용</span>
        <p>Hugging Face의 <code>datasets</code> 라이브러리를 통해 공개된 의학 Q&A 데이터셋을 쉽게 사용할 수 있습니다.</p>
        <pre><code class="language-python">
# pip install datasets
from datasets import load_dataset

# PubMedQA 데이터셋 로드
# pqa_labeled: 전문가가 직접 레이블링한 데이터
dataset = load_dataset("pubmed_qa", "pqa_labeled")

# 데이터 구조 확인
print(dataset['train'][0])
# {'pubid': 21644827, 
#  'question': '...', 
#  'context': {'contexts': [...], 'labels': [...], 'meshes': [...], 'reasoning_required_pred': True, 'reasoning_free_pred': True}, 
#  'long_answer': '...', 
#  'final_decision': 'yes'}

# 이 데이터셋의 'context'를 Vector DB에 저장하고, 'question'으로 검색하여 'long_answer'를 생성/비교하는 RAG 파이프라인을 구축할 수 있습니다.
        </code></pre>

        <hr>

        <h2>CH 05. RAG 시스템 평가 및 운영: RAGAS와 LangSmith 📊</h2>
        
        <h3>학습 목표</h3>
        <ul>
            <li>RAG 시스템의 성능을 평가하는 핵심 지표를 이해합니다.</li>
            <li>RAGAS를 사용하여 RAG 파이프라인을 정량적으로 평가할 수 있습니다.</li>
            <li>LangSmith를 사용하여 RAG 애플리케이션의 동작을 추적하고 디버깅할 수 있습니다.</li>
        </ul>

        <h3>이론 설명: RAG, 평가 없이는 개선도 없다</h3>
        <p>훌륭한 RAG 시스템을 구축하는 것은 '만드는 것'에서 끝나지 않습니다. '측정하고 개선하는' 과정이 반드시 동반되어야 합니다. RAG 시스템의 평가는 크게 두 가지 관점에서 이루어집니다.</p>
        <ol>
            <li><strong>컴포넌트별 평가:</strong> 검색(Retrieval)과 생성(Generation) 각 단계의 성능을 개별적으로 평가합니다.
                <ul>
                    <li><strong>검색 평가 (Context Relevancy / Precision):</strong> 검색된 문서가 질문과 얼마나 관련이 있는가?</li>
                    <li><strong>생성 평가 (Faithfulness, Answer Relevancy):</strong> 생성된 답변이 검색된 문서에 기반하고 있는가? (환각은 없는가?), 그리고 질문의 의도에 부합하는가?</li>
                </ul>
            </li>
            <li><strong>파이프라인 전체 평가:</strong> 최종적으로 생성된 답변이 사용자의 기대를 얼마나 충족시키는가를 종합적으로 평가합니다.</li>
        </ol>

        <h3>실습 1: RAGAS를 이용한 파이프라인 평가</h3>
        <p><strong>RAGAS</strong>는 RAG 시스템을 평가하기 위해 만들어진 특화된 프레임워크입니다. 위에서 언급한 주요 지표들을 LLM을 사용하여 정량적으로 측정해줍니다.</p>

        <span class="code-title">Python Code: RAGAS 평가 실행</span>
        <pre><code class="language-python">
from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_relevancy,
    context_recall,
)
from datasets import Dataset

# 평가 데이터셋 준비 (질문, 정답, 생성된 답변, 검색된 컨텍스트)
# 이 데이터는 앞선 실습에서 구축한 RAG 파이프라인을 통해 생성해야 합니다.
eval_data = {
    'question': ["What is the main cause of insulin resistance?"],
    'answer': ["The main cause of insulin resistance is a combination of genetic and lifestyle factors, primarily obesity and physical inactivity."],
    'contexts': [["Insulin resistance is a health condition where your body's cells become less responsive to the hormone insulin...", "Obesity, particularly excess belly fat, and a sedentary lifestyle are major contributors."]],
    'ground_truth': ["The primary cause of insulin resistance is linked to excess weight, especially visceral fat, and a lack of physical activity. Genetic factors can also play a role."]
}
dataset = Dataset.from_dict(eval_data)

# 평가 실행
result = evaluate(
    dataset=dataset,
    metrics=[
        context_relevancy, # 검색된 컨텍스트와 질문의 관련성
        faithfulness,      # 답변이 컨텍스트에 얼마나 근거하는가
        answer_relevancy,  # 답변이 질문과 얼마나 관련있는가
    ],
)

# 결과 확인
print(result)
# {'context_relevancy': 0.95, 'faithfulness': 1.0, 'answer_relevancy': 0.98}
        </code></pre>
        <p>$$ \text{Faithfulness} = \frac{\text{Number of claims supported by context}}{\text{Total number of claims in answer}} $$</p>

        <h3>실습 2: LangSmith로 RAG 파이프라인 추적하기</h3>
        <p><strong>LangSmith</strong>는 LangChain 개발사가 만든 LLM 애플리케이션을 위한 MLOps 플랫폼입니다. RAG 파이프라인의 모든 단계를 시각적으로 추적(Tracing)하고, 각 단계의 입출력, 소요 시간, 에러 등을 상세하게 확인할 수 있어 디버깅과 성능 분석에 매우 유용합니다.</p>
        
        <p>LangSmith를 사용하려면 환경 변수를 설정하기만 하면 됩니다. LangChain 코드는 자동으로 LangSmith와 연동됩니다.</p>
        <span class="code-title">환경 변수 설정</span>
        <pre><code class="language-bash">
export LANGCHAIN_TRACING_V2="true"
export LANGCHAIN_API_KEY="YOUR_LANGSMITH_API_KEY"
export LANGCHAIN_PROJECT="My RAG Project"
        </code></pre>
        <p>이후 RAG 파이프라인을 실행하면, 모든 과정이 LangSmith 대시보드에 자동으로 기록됩니다. 사용자의 질문부터 시작해서 -> 쿼리 변환 -> 문서 검색 -> 리랭킹 -> LLM 프롬프트 구성 -> 최종 답변 생성에 이르는 전 과정을 한눈에 파악하고 병목 지점이나 오류의 원인을 쉽게 찾을 수 있습니다.</p>

    </div>
</body>
</html>
